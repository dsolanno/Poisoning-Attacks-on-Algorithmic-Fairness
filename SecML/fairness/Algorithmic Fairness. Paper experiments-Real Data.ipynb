{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import warnings\n",
    "from scipy import integrate\n",
    "\n",
    "from scipy import stats\n",
    "random_state = 999\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "##Â General importsÃ‡\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## SKLearn imports\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "## AIF360 imports\n",
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "            import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "\n",
    "#SEC_ML imports\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.classifiers import CClassifierSVM, CClassifierLogistic\n",
    "from secml.ml.kernels import CKernelRBF, CKernelLinear\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "from secml.data.splitter import CDataSplitterKFold\n",
    "\n",
    "# Poisoning attacks\n",
    "from secml.adv.attacks import CAttackPoisoningSVM\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_palette=sns.diverging_palette(255, 133, l=60, n=12, center=\"dark\")\n",
    "sns.palplot(sns.color_palette(\"Paired\", 12))\n",
    "sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\", rc={\"font.size\":16,\"axes.titlesize\":20,\"axes.labelsize\":16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "SEED = 999\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def get_data(dataset_used = \"compas\"):\n",
    "    # import dataset\n",
    "    #sdataset_used = \"compas\" # \"adult\", \"german\", \"compas\"\n",
    "    protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "    if dataset_used == \"adult\":\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_adult,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "    elif dataset_used == \"german\":\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['sex'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            ##Â Changing labels to 0-1\n",
    "            dataset_orig.labels[dataset_orig.labels==2]=0\n",
    "            dataset_orig.unfavorable_label=0.0\n",
    "\n",
    "        else:\n",
    "            privileged_groups = [{'age': 1}]\n",
    "            unprivileged_groups = [{'age': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['age'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.1,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }    \n",
    "\n",
    "    elif dataset_used == \"compas\":\n",
    "        if protected_attribute_used == 1:     \n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_compas,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "\n",
    "    #random seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    dataset_aif360 = dataset_orig\n",
    "    \n",
    "    # Split into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_vt = dataset_aif360.split([0.2], shuffle=True)\n",
    "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)\n",
    "    \n",
    "    dataset_aif360 = dataset_orig_train.copy()\n",
    "    \n",
    "    SENSIBLE_ATT_INDEX = dataset_orig.feature_names.index(dataset_orig.protected_attribute_names[0])\n",
    "\n",
    "    ## Correcting labels assignation\n",
    "    if dataset_aif360.unfavorable_label != 0:\n",
    "        Y = dataset_aif360.labels\n",
    "        Y[Y == dataset_aif360.unfavorable_label] = -1\n",
    "        Y[Y == dataset_aif360.favorable_label] = 1\n",
    "        Y[Y == -1] = 0\n",
    "\n",
    "        dataset_aif360.unfavorable_label = 0\n",
    "        dataset_aif360.favorable_label = 1\n",
    "    #np.delete(dataset_aif360.features, SENSIBLE_ATT_INDEX, axis=1)    \n",
    "    sec_ml_dataset = CDataset(dataset_aif360.features , dataset_aif360.labels)\n",
    "    \n",
    "    return sec_ml_dataset.X.get_data(), sec_ml_dataset.Y.get_data(), SENSIBLE_ATT_INDEX\n",
    "    \n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def get_data2(dataset_used = \"compas\"):\n",
    "    # import dataset\n",
    "    #sdataset_used = \"compas\" # \"adult\", \"german\", \"compas\"\n",
    "    protected_attribute_used = 1 # 1, 2\n",
    "\n",
    "    if dataset_used == dataset_used:\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_adult(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_adult,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "    elif dataset_used == \"german\":\n",
    "        if protected_attribute_used == 1:\n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['sex'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.05,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }\n",
    "            ##Â Changing labels to 0-1\n",
    "            dataset_orig.labels[dataset_orig.labels==2]=0\n",
    "            dataset_orig.unfavorable_label=0.0\n",
    "\n",
    "        else:\n",
    "            privileged_groups = [{'age': 1}]\n",
    "            unprivileged_groups = [{'age': 0}]\n",
    "            dataset_orig = load_preproc_data_german(['age'])\n",
    "            optim_options = {\n",
    "                \"distortion_fun\": get_distortion_german,\n",
    "                \"epsilon\": 0.1,\n",
    "                \"clist\": [0.99, 1.99, 2.99],\n",
    "                \"dlist\": [.1, 0.05, 0]\n",
    "            }    \n",
    "\n",
    "    elif dataset_used == \"compas\":\n",
    "        if protected_attribute_used == 1:     \n",
    "            privileged_groups = [{'sex': 1}]\n",
    "            unprivileged_groups = [{'sex': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['sex'])\n",
    "        else:\n",
    "            privileged_groups = [{'race': 1}]\n",
    "            unprivileged_groups = [{'race': 0}]\n",
    "            dataset_orig = load_preproc_data_compas(['race'])\n",
    "\n",
    "        optim_options = {\n",
    "            \"distortion_fun\": get_distortion_compas,\n",
    "            \"epsilon\": 0.05,\n",
    "            \"clist\": [0.99, 1.99, 2.99],\n",
    "            \"dlist\": [.1, 0.05, 0]\n",
    "        }\n",
    "\n",
    "\n",
    "    #random seed\n",
    "    np.random.seed(1)\n",
    "\n",
    "    dataset_aif360 = dataset_orig\n",
    "    \n",
    "    # Split into train, validation, and test\n",
    "    dataset_orig_train, dataset_orig_vt = dataset_aif360.split([0.8], shuffle=True)\n",
    "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split([0.5], shuffle=True)\n",
    "    \n",
    "    dataset_aif360 = dataset_orig_vt.copy()\n",
    "    \n",
    "    SENSIBLE_ATT_INDEX = dataset_orig.feature_names.index(dataset_orig.protected_attribute_names[0])\n",
    "\n",
    "    ## Correcting labels assignation\n",
    "    if dataset_aif360.unfavorable_label != 0:\n",
    "        Y = dataset_aif360.labels\n",
    "        Y[Y == dataset_aif360.unfavorable_label] = -1\n",
    "        Y[Y == dataset_aif360.favorable_label] = 1\n",
    "        Y[Y == -1] = 0\n",
    "\n",
    "        dataset_aif360.unfavorable_label = 0\n",
    "        dataset_aif360.favorable_label = 1\n",
    "    #np.delete(dataset_aif360.features, SENSIBLE_ATT_INDEX, axis=1)    \n",
    "    sec_ml_dataset = CDataset(dataset_aif360.features , dataset_aif360.labels)\n",
    "    \n",
    "    return sec_ml_dataset.X.get_data(), sec_ml_dataset.Y.get_data(), SENSIBLE_ATT_INDEX\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##Â 2. Creating custom Weighted CLoss to solve the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from secml.ml.classifiers.loss import CLossClassification, CLossLogistic\n",
    "from secml.array import CArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CLossDisparateImpact(CLossClassification):\n",
    "    \"\"\"Surrogate function of disparate impact.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    class_type : 'log'\n",
    "    suitable_for : 'classification'\n",
    "\n",
    "    \"\"\"\n",
    "    __class_type = 'dimp_log'\n",
    "\n",
    "    def __init__(self, _privileged_condition):\n",
    "        self._privileged_condition = CArray(_privileged_condition)\n",
    "\n",
    "    def unprivileged(self):\n",
    "        \"\"\"Give 1 to unprivileged, 0 to privileged\"\"\"\n",
    "        y = CArray.zeros(self._privileged_condition.size)\n",
    "        y[self._privileged_condition == 0] = 1\n",
    "        return y\n",
    "\n",
    "    def loss(self, y_true, score, pos_label=1):\n",
    "        \"\"\"Computes loss_priv-loss_unpriv, which is what we aim to max\"\"\"\n",
    "        # give 1 to unpriv, 0 to priv\n",
    "        y = self.unprivileged()\n",
    "        p_priv = (y == 0).sum() / y.size\n",
    "        p_unpriv = (y == 1).sum() / y.size\n",
    "        # loss = (score >= 0) != y  # zero-one loss\n",
    "        loss = CLossLogistic().loss(y_true=y, score=score)  # smoothed version\n",
    "        loss[y == 1] *= -p_priv / p_unpriv  # rebalance class weights\n",
    "        return loss\n",
    "\n",
    "    def dloss(self, y_true, score, pos_label=1):\n",
    "        \"\"\"Computes the derivative of the loss vs score.\"\"\"\n",
    "        y = self.unprivileged()\n",
    "        p_priv = (y == 0).sum() / y.size\n",
    "        p_unpriv = (y == 1).sum() / y.size\n",
    "        grad = CLossLogistic().dloss(y, score, pos_label)\n",
    "        grad[y == 1] *= -p_priv / p_unpriv  # rebalance class weights\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_disparate_impact(y,sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=False):\n",
    "    \n",
    "    privileged = y[sensible_att_vals == privileged_classes]\n",
    "    unprivileged = y[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    unprivileged_favorable = unprivileged[unprivileged==favorable_output]\n",
    "    privileged_favorable = privileged[privileged==favorable_output]\n",
    "    \n",
    "    n1 =  (len(unprivileged_favorable)/ len(unprivileged))\n",
    "    n2 = (len(privileged_favorable)/ len(privileged))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tUnprivileged favorable1: \", n1)\n",
    "        print(\"\\tPrivileged favorable2: \", n2)\n",
    "     \n",
    "    disparate_impact = n1 - n2#(max(n2,0.1)) \n",
    "    return disparate_impact\n",
    "\n",
    "def calculate_error_rate_ratio(y_true, y_pred,sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=True):\n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_num_errors = len(privileged_y_true) - (len(np.where(np.isclose(privileged_y_true, privileged_y_pred))[0]))\n",
    "    unprivileged_num_errors = len(unprivileged_y_true) - (len(np.where(np.isclose(unprivileged_y_true, unprivileged_y_pred))[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tN1: \", n1)\n",
    "        print(\"\\tN2: \", n2)\n",
    "        \n",
    "    \n",
    "        \n",
    "    error_rate = (unprivileged_num_errors / len(unprivileged_y_true)) / (privileged_num_errors / len(privileged_y_true))\n",
    "    return error_rate\n",
    "\n",
    "#12[(ð¹ð‘ƒð‘…ð·=unprivilegedâˆ’ð¹ð‘ƒð‘…ð·=privileged)+(ð‘‡ð‘ƒð‘…ð·=unprivilegedâˆ’ð‘‡ð‘ƒð‘…ð·=privileged))]\n",
    "def get_average_odds_difference(y_true, y_pred, sensible_att_vals, privileged_classes=1, favorable_output=1):\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)    \n",
    "\n",
    "    sensible_att_vals = np.array(sensible_att_vals)\n",
    "                                 \n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "                                 \n",
    "                                 \n",
    "    FPR_unprivileged = get_false_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    FPR_privileged = get_false_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    TPR_unprivileged = get_true_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    TPR_privileged = get_true_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "                              \n",
    "    return 0.5 * ((FPR_unprivileged - FPR_privileged) + (TPR_unprivileged - TPR_privileged))\n",
    "    \n",
    "    \n",
    "\n",
    "def get_false_positive_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp1 = y_pred[y_true!=favorable_output]\n",
    "    fp = _tmp1[_tmp1 == favorable_output]\n",
    "    \n",
    "    N = len(y_true[y_true != favorable_output])\n",
    "    \n",
    "    if N == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fp) / N\n",
    "\n",
    "def get_true_positive_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp1 = y_pred[y_true==favorable_output]\n",
    "    fp = _tmp1[_tmp1 == favorable_output]\n",
    "    \n",
    "    P = len(y_true[y_true == favorable_output])\n",
    "    \n",
    "    if N == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fp) / P\n",
    "    \n",
    "    \n",
    "def get_false_negative_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp = y_pred[y_true==favorable_output]\n",
    "    \n",
    "    fn = _tmp[_tmp != favorable_output]\n",
    "    \n",
    "    P = len(y_true[y_true != favorable_output])\n",
    "    \n",
    "    if P == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fn) / P\n",
    "\n",
    "def get_error_rates(y_true, y_pred, sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=False):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)    \n",
    "\n",
    "    sensible_att_vals = np.array(sensible_att_vals)\n",
    "    \n",
    "    \n",
    "    \n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "    \"\"\"\n",
    "    privileged_num_errors = len(privileged_y_true) - (len(np.where(np.isclose(privileged_y_true, privileged_y_pred))[0]))\n",
    "    unprivileged_num_errors = len(unprivileged_y_true) - (len(np.where(np.isclose(unprivileged_y_true, unprivileged_y_pred))[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tN1: \", n1)\n",
    "        print(\"\\tN2: \", n2)\n",
    "\n",
    "        error_rate = (unprivileged_num_errors / len(unprivileged_y_true)) / (privileged_num_errors / len(privileged_y_true))\n",
    "    \"\"\"\n",
    "    \n",
    "    FNR_privileged = get_false_negative_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    FNR_unprivileged = get_false_negative_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    \n",
    "    FPR_privileged = get_false_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    FPR_unprivileged = get_false_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tFNR_1: \", FNR_privileged)\n",
    "        print(\"\\tFNR_2: \", FNR_unprivileged)\n",
    "        print(\"\\tFPR_1: \", FPR_privileged)\n",
    "        print(\"\\tFPR_2: \", FPR_unprivileged)\n",
    "    \n",
    "    FNR = -1\n",
    "    FPR = -1\n",
    "    \n",
    "    try:\n",
    "        FNR = FNR_unprivileged / FNR_privileged\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        FPR = FPR_unprivileged / FPR_privileged\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    return ({\"FNR\": FNR, \"FNR_privileged\":FNR_privileged, \"FNR_unprivileged\":FNR_unprivileged, \"FNR\": 1}, {\"FPR\":FPR, \"FPR_privileged\":FPR_privileged, \"FPR_unprivileged\":FPR_unprivileged})\n",
    "\n",
    "\n",
    "\n",
    "def train_LogReg(training_set, test_set):\n",
    "\n",
    "    \n",
    "    # Metric to use for training and performance evaluation\n",
    "    # Creation of the multiclass classifier\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    #clf = CClassifierSVM(kernel=CKernelRBF()) # Radial Basis Function (RBF) kernel.\n",
    "    #clf = CClassifierSVM(kernel=CKernelLinear()) # Linear kernel.\n",
    "    clf = CClassifierLogistic()\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1, 10]}#, 'kernel.gamma': [0.1]}#, 5, 10, 25, 50, 100]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    \n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    print(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=training_set,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "\n",
    "    print(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    # We can now fit the classifier\n",
    "    clf.fit(training_set)\n",
    "    print(\"Training of classifier complete!\")\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(test_set.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=test_set.Y, y_pred=y_pred)\n",
    "\n",
    "    print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "    \n",
    "    return clf, acc\n",
    "\n",
    "def train_SVM(training_set, test_set):\n",
    "\n",
    "    \n",
    "    # Metric to use for training and performance evaluation\n",
    "    # Creation of the multiclass classifier\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    #clf = CClassifierSVM(kernel=CKernelRBF()) # Radial Basis Function (RBF) kernel.\n",
    "    clf = CClassifierSVM(kernel=CKernelLinear()) # Linear kernel.\n",
    "    #clf = CClassifierLogistic()\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1, 10]}#,'kernel.gamma': [0.1, 5, 10, 25, 50, 100]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    \n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    print(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=training_set,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "\n",
    "    print(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    # We can now fit the classifier\n",
    "    clf.fit(training_set)\n",
    "    print(\"Training of classifier complete!\")\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(test_set.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=test_set.Y, y_pred=y_pred)\n",
    "\n",
    "    print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "    \n",
    "    return clf, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_adversarial_attack(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois=0.2):\n",
    "\n",
    "    print(\" ==> Adversarial attack. Percentage of samples: {} \".format(percentage_pois))\n",
    "    metric = CMetricAccuracy()\n",
    "    NUM_SAMPLES_TRAIN = training_set.num_samples\n",
    "    n_poisoning_points = int(NUM_SAMPLES_TRAIN * percentage_pois) # Number of poisoning points to generate\n",
    "    print(\"Creating {} poisoning samples \".format(n_poisoning_points))\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.05,\n",
    "        'eta_min': 0.05,\n",
    "        'eta_max': None,\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-6\n",
    "    }\n",
    "\n",
    "\n",
    "    pois_attack = CAttackPoisoningLogisticRegression(classifier=surrogate_clf,\n",
    "                                      training_data=training_set,\n",
    "                                      surrogate_classifier=surrogate_clf,\n",
    "                                      surrogate_data=validation_set,\n",
    "                                      val=validation_set,\n",
    "                                      distance='l1',\n",
    "                                      dmax=10,\n",
    "                                      lb=validation_set.X.min(), ub=validation_set.X.max(),\n",
    "                                      solver_params=solver_params,\n",
    "                                      random_seed=random_state,\n",
    "                                      init_type=\"random\")\n",
    "\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "    \n",
    "    dimp_loss = CLossDisparateImpact(privileged_condition_validation)\n",
    "    pois_attack._attacker_loss = dimp_loss\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(test_set.X, test_set.Y)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    \n",
    "    pois_tr = training_set.deepcopy().append(pois_ds)  # Join the training set with the poisoning points\n",
    "   \n",
    "    return pois_ds, pois_tr\n",
    "\n",
    "\n",
    "def execute_normal_poisoning_attack(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois=0.2):\n",
    "\n",
    "    metric = CMetricAccuracy()\n",
    "    NUM_SAMPLES_TRAIN = training_set.num_samples\n",
    "    n_poisoning_points = int(NUM_SAMPLES_TRAIN * percentage_pois) # Number of poisoning points to generate\n",
    "    print(\"Creating {} poisoning samples \".format(n_poisoning_points))\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.05,\n",
    "        'eta_min': 0.05,\n",
    "        'eta_max': None,\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-6\n",
    "    }\n",
    "\n",
    "\n",
    "    pois_attack = CAttackPoisoningLogisticRegression(classifier=surrogate_clf,\n",
    "                                      training_data=training_set,\n",
    "                                      surrogate_classifier=surrogate_clf,\n",
    "                                      surrogate_data=validation_set,\n",
    "                                      val=validation_set,\n",
    "                                      distance='l1',\n",
    "                                      dmax=10,\n",
    "                                      lb=validation_set.X.min(), ub=validation_set.X.max(),\n",
    "                                      solver_params=solver_params,\n",
    "                                      random_seed=random_state,\n",
    "                                      init_type=\"random\")\n",
    "\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "    \n",
    "    #dimp_loss = CLossDisparateImpact(privileged_condition_validation)\n",
    "    #pois_attack._attacker_loss = dimp_loss\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(test_set.X, test_set.Y)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    \n",
    "    pois_tr = training_set.deepcopy().append(pois_ds)  # Join the training set with the poisoning points\n",
    "   \n",
    "    return pois_ds, pois_tr\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## 4. Generate Disparate Impact scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "N=9 #Max euclidean distance between average of distributions\n",
    "n=1\n",
    "dimp_in_data = []\n",
    "euc_distances = []\n",
    "dimp_scenarios = []\n",
    "\n",
    "## Generating data\n",
    "X,y,sensitive_att_index = get_data()\n",
    "formatted_X=X ##Â Concatenating X with sensible att\n",
    "\n",
    "print(\"X_shape: \", X.shape)\n",
    "sensible_att_all = X[:,sensitive_att_index]\n",
    "sec_ml_dataset_all = CDataset(X, y)\n",
    "\n",
    "dimp_in_data.append(calculate_disparate_impact(sec_ml_dataset_all.Y.get_data(), sensible_att_all)) \n",
    "\n",
    "## Splitting data. \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(formatted_X, y, test_size=0.2, random_state=random_state)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=random_state)\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "training = CDataset(X_train, y_train)\n",
    "training_sensible_att = X_train[:,sensitive_att_index]\n",
    "\n",
    "validation = CDataset(X_val, y_val)\n",
    "validation_sensible_att = X_val[:,sensitive_att_index]\n",
    "val_lambda = np.zeros(validation.num_samples)\n",
    "\n",
    "## Creating lambda vector\n",
    "val_lambda[np.where((validation_sensible_att==0) & (y_val==0))[0]] == 1 ##Â Unprivileged denied\n",
    "val_lambda[np.where((validation_sensible_att==0) & (y_val==1))[0]] == 1 ##Â Unprivileged granted\n",
    "val_lambda[np.where((validation_sensible_att==1) & (y_val==0))[0]] == -1 ##Â Privileged denied\n",
    "val_lambda[np.where((validation_sensible_att==1) & (y_val==1))[0]] == -1 ##Â Privileged granted\n",
    "\n",
    "test = CDataset(X_test, y_test)\n",
    "test_sensible_att = X_test[:,sensitive_att_index]\n",
    "\n",
    "\n",
    "## GENERATING DATA FOR WHITE BOX ATTACK\n",
    "X2,y2,sensitive_att_index2 = get_data2()\n",
    "formatted_X2=X2 ##Â Concatenating X with sensible att\n",
    "\n",
    "sec_ml_dataset_all2 = CDataset(X2, y2)\n",
    "sensible_att_all2 = sec_ml_dataset_all2.X.get_data()[:,sensitive_att_index2]\n",
    "\n",
    "## Splitting data. \n",
    "X_train_val2, X_test2, y_train_val2, y_test2 = train_test_split(formatted_X2, y2, test_size=0.2, random_state=random_state)\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train_val2, y_train_val2, test_size=0.5, random_state=random_state)\n",
    "\n",
    "training2 = CDataset(X_train2, y_train2)\n",
    "training_sensible_att2 = X_train2.ravel()\n",
    "\n",
    "validation2 = CDataset(X_val2, y_val2)\n",
    "validation_sensible_att2 = X_val2.ravel()\n",
    "val_lambda2 = np.zeros(validation2.num_samples)\n",
    "\n",
    "test2 = CDataset(X_test2, y_test2)\n",
    "test_sensible_att2 = X_test2.ravel()\n",
    "\n",
    "scenario = {\n",
    "    \"name\": \"Use case 4 - {}\".format(n),\n",
    "    \"description\": \"Disparate impact attack. \\n Euclidean distance between group averages: {}\\n\".format(n),\n",
    "    \"training\": training,\n",
    "    \"training_sensible_att\" : training_sensible_att,\n",
    "    \"validation\" : validation,\n",
    "    \"validation_sensible_att\" : validation_sensible_att,\n",
    "    \"lambda_validation\" : validation_sensible_att,\n",
    "    \"test\": test,\n",
    "    \"test_sensible_att\" : test_sensible_att,\n",
    "    \"all_data\" : sec_ml_dataset_all,\n",
    "    \"all_sensible_att\" : sensible_att_all,        \n",
    "    \"black_box_training\": training2,\n",
    "    \"black_box_training_sensible_att\" : training_sensible_att2,\n",
    "    \"black_box_validation\" : validation2,\n",
    "    \"black_box_validation_sensible_att\" : validation_sensible_att2,\n",
    "    \"black_box_lambda_validation\" : val_lambda2,\n",
    "    \"black_box_test\": test2,\n",
    "    \"black_box_test_sensible_att\" : test_sensible_att2,\n",
    "    \"black_box_all_data\" : sec_ml_dataset_all2,\n",
    "    \"black_box_all_sensible_att\" : sensible_att_all2,\n",
    "}\n",
    "    \n",
    "    \n",
    "dimp_scenarios.append(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scenario in dimp_scenarios:\n",
    "    print(\"\\n\\n ==== {} ====\".format(scenario['name']))\n",
    "    print(\"    - {}\\n\".format(scenario['description']))\n",
    "    \n",
    "    ################################\n",
    "    ### ORIGINAL CLF PERFORMANCE ###\n",
    "    ################################\n",
    "    original_model, original_acc = train_LogReg(scenario[\"training\"], scenario[\"test\"])\n",
    "    \n",
    "    orig_y_pred = original_model.predict(scenario[\"test\"].X)\n",
    "    orig_FNR, orig_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    orig_disparate_imp = calculate_disparate_impact(orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    orig_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['original_classifier'] = original_model\n",
    "    scenario['original_acc'] = original_acc\n",
    "    scenario['orig_d_imp'] = orig_disparate_imp\n",
    "    scenario['orig_FNR'] = orig_FNR\n",
    "    scenario['orig_FPR'] = orig_FPR\n",
    "    scenario['orig_odds'] = orig_odds_diff\n",
    "    \n",
    "\n",
    "    ########################\n",
    "    ### WHITE BOX ATTACK ###\n",
    "    ########################\n",
    "    white_pois_clf = deepcopy(original_model)\n",
    "    \n",
    "    privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "    privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "    \n",
    "    \n",
    "    white_pois_points, white_pois_tr = execute_adversarial_attack(white_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ##Â Retraining with poisoned points\n",
    "    white_pois_clf = white_pois_clf.fit(white_pois_tr)\n",
    "    white_pois_y_pred = white_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    metric = CMetricAccuracy()\n",
    "    white_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=white_pois_y_pred)\n",
    "    white_pois_disparate_imp = calculate_disparate_impact(white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    white_pois_FNR, white_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    white_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['white_poisoned_classifier'] = white_pois_clf\n",
    "    scenario['white_poisoned_points'] = white_pois_points\n",
    "    scenario['white_pois_d_imp'] = white_pois_disparate_imp\n",
    "    scenario['white_pois_y_pred'] = white_pois_y_pred\n",
    "    scenario['white_pois_acc'] = white_pois_acc\n",
    "    scenario['white_pois_FNR'] = white_pois_FNR\n",
    "    scenario['white_pois_FPR'] = white_pois_FPR\n",
    "    scenario['white_odds'] = white_odds_diff\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    ### BLACK BOX ATTACK ###\n",
    "    ########################\n",
    "    real_model, real_acc = train_SVM(scenario[\"training\"], scenario[\"test\"])\n",
    "    \n",
    "    surrogate_clf = deepcopy(original_model)\n",
    "    \n",
    "    black_pois_points, black_pois_tr = execute_adversarial_attack(surrogate_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ##Â Retraining with poisoned points\n",
    "    \n",
    "    black_pois_clf = deepcopy(real_model)\n",
    "    black_pois_clf = black_pois_clf.fit(black_pois_tr)\n",
    "    black_pois_y_pred = black_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    black_pois_acc = metric.performance_score(y_true=scenario[\"test\"].Y, y_pred=black_pois_y_pred)\n",
    "    black_pois_disparate_imp = calculate_disparate_impact(black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    black_pois_FNR, black_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    black_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['black_poisoned_classifier'] = black_pois_clf\n",
    "    scenario['black_poisoned_points'] = black_pois_points\n",
    "    scenario['black_pois_d_imp'] = black_pois_disparate_imp\n",
    "    scenario['black_pois_y_pred'] = black_pois_y_pred\n",
    "    scenario['black_pois_acc'] = black_pois_acc\n",
    "    scenario['black_pois_FNR'] = black_pois_FNR\n",
    "    scenario['black_pois_FPR'] = black_pois_FPR\n",
    "    scenario['black_odds'] = black_odds_diff\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ### CLASSIC POISONING ATTACK ###\n",
    "    ################################\n",
    "    normal_pois_clf = deepcopy(original_model)\n",
    "    \n",
    "    privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "    privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "    \n",
    "    \n",
    "    normal_pois_points, normal_pois_tr = execute_normal_poisoning_attack(normal_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ##Â Retraining with poisoned points\n",
    "    normal_pois_clf = normal_pois_clf.fit(normal_pois_tr)\n",
    "    normal_pois_y_pred = normal_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    metric = CMetricAccuracy()\n",
    "    normal_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=normal_pois_y_pred)\n",
    "    print(\"->> normal\")\n",
    "    normal_pois_disparate_imp = calculate_disparate_impact(normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    normal_pois_FNR, normal_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    \n",
    "\n",
    "    scenario['normal_poisoned_classifier'] = normal_pois_clf\n",
    "    scenario['normal_poisoned_points'] = normal_pois_points\n",
    "    scenario['normal_pois_d_imp'] = normal_pois_disparate_imp\n",
    "    scenario['normal_odds'] = normal_odds_diff\n",
    "    scenario['normal_pois_y_pred'] = normal_pois_y_pred\n",
    "    scenario['normal_pois_acc'] = normal_pois_acc\n",
    "    scenario['normal_pois_FNR'] = normal_pois_FNR\n",
    "    scenario['normal_pois_FPR'] = normal_pois_FPR\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "def plot_disparate_impact(scenarios, data_dimp=None , n_scenarios=1, title=None):\n",
    "    \n",
    "    x1 = [n for n in range(n_scenarios)]\n",
    "    \n",
    "    x1 = 1\n",
    "    x2 = 2.5\n",
    "    x3 = 4\n",
    "    \n",
    "    fig=plt.figure(figsize=[12,8])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(2,4) # 2 rows, 3 columns\n",
    "\n",
    "    ax1=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "    ax1.bar(x1,[float(UC[\"original_acc\"]) for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax1.bar(x2,[float(UC[\"white_pois_acc\"]) for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax1.bar(x3,[float(UC[\"black_pois_acc\"]) for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    \n",
    "\n",
    "    ax2=fig.add_subplot(gs[0,2]) # First row, first column\n",
    "    ax2.set_title(\"Demographic parity\")\n",
    "    ax2.bar(x1,[UC[\"orig_d_imp\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #if data_dimp is not None:\n",
    "    #ax2.bar(0,data_dimp, color=\"darkgrey\", label=\"Original data\")\n",
    "    ax2.bar(x2,[UC[\"white_pois_d_imp\"] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2.bar(x3,[UC[\"black_pois_d_imp\"] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    ax2b=fig.add_subplot(gs[0,3]) # First row, second column\n",
    "    ax2b.set_title(\"Average odds difference\")\n",
    "\n",
    "    ax2b.bar(x1, [UC[\"orig_odds\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax2b.bar(x2, [UC[\"white_odds\"] for UC in scenarios], color=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    ax2b.bar(x3, [UC[\"black_odds\"] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "\n",
    "    \n",
    "    ax3=fig.add_subplot(gs[1,0]) # First row, second column\n",
    "    ax3.set_title(\"FNR privileged\")\n",
    "    ax3.bar(x1,[UC[\"orig_FNR\"][\"FNR_privileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax3.bar(x2,[UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax3.bar(x3,[UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    ax4=fig.add_subplot(gs[1,1]) # First row, third column\n",
    "    ax4.set_title(\"FNR unprivileged\")\n",
    "    ax4.bar(x1,[UC[\"orig_FNR\"][\"FNR_unprivileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax4.bar(x2,[UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax4.bar(x3,[UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    #ax4.bar([], [], color=\"gray\", label=\"Disparate impact in the data\")\n",
    "    ax4.legend(bbox_to_anchor=(1.8, -0.1),fontsize=15)\n",
    "    \n",
    "    ax5=fig.add_subplot(gs[1,2]) # First row, second column\n",
    "    ax5.set_title(\"FPR privileged\")\n",
    "    ax5.bar(x1,[UC[\"orig_FPR\"][\"FPR_privileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax5.bar(x2,[UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax5.bar(x3,[UC[\"black_pois_FPR\"]['FPR_privileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    ax6=fig.add_subplot(gs[1,3]) # First row, third column\n",
    "    ax6.set_title(\"FPR unprivileged\")\n",
    "    ax6.bar(x1,[UC[\"orig_FPR\"][\"FPR_unprivileged\"] for UC in scenarios], color=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax6.bar(x2,[UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], color=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax6.bar(x3,[UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], color=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "\n",
    "    \n",
    "    ax1.set_xticks([])\n",
    "    ax2.set_xticks([])\n",
    "    ax3.set_xticks([])\n",
    "    ax4.set_xticks([])\n",
    "    ax5.set_xticks([])\n",
    "    ax6.set_xticks([])\n",
    "    \n",
    "    \n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_disparate_impact(dimp_scenarios, dimp_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGE = np.arange(0.05, 0.31, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_results = []\n",
    "for i in range(5):\n",
    "    scenarios2 = []\n",
    "    for perc_pois in RANGE:\n",
    "        scenario = deepcopy(dimp_scenarios[0])\n",
    "\n",
    "        print(scenario[\"training\"])\n",
    "\n",
    "        print(\"\\n\\n ==== {}-{} ====\".format(scenario['name'], perc_pois))\n",
    "        print(\"    - {}\\n\".format(scenario['description']))\n",
    "\n",
    "        ################################\n",
    "        ### ORIGINAL CLF PERFORMANCE ###\n",
    "        ################################\n",
    "        original_model, original_acc = train_LogReg(scenario[\"training\"], scenario[\"test\"])\n",
    "\n",
    "        orig_y_pred = original_model.predict(scenario[\"test\"].X)\n",
    "        orig_FNR, orig_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        orig_disparate_imp = calculate_disparate_impact(orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        orig_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "        scenario['original_classifier'] = original_model\n",
    "        scenario['original_acc'] = original_acc\n",
    "        scenario['orig_d_imp'] = orig_disparate_imp\n",
    "        scenario['orig_FNR'] = orig_FNR\n",
    "        scenario['orig_FPR'] = orig_FPR\n",
    "        scenario['orig_odds'] = orig_odds_diff\n",
    "\n",
    "\n",
    "        ########################\n",
    "        ### WHITE BOX ATTACK ###\n",
    "        ########################\n",
    "        white_pois_clf = deepcopy(original_model)\n",
    "\n",
    "        privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "        privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "\n",
    "\n",
    "        white_pois_points, white_pois_tr = execute_adversarial_attack(white_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"], perc_pois)\n",
    "        ##Â Retraining with poisoned points\n",
    "        white_pois_clf = white_pois_clf.fit(white_pois_tr)\n",
    "        white_pois_y_pred = white_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "        metric = CMetricAccuracy()\n",
    "        white_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=white_pois_y_pred)\n",
    "        white_pois_disparate_imp = calculate_disparate_impact(white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        white_pois_FNR, white_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        white_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "        scenario['white_poisoned_classifier'] = white_pois_clf\n",
    "        scenario['white_poisoned_points'] = white_pois_points\n",
    "        scenario['white_pois_d_imp'] = white_pois_disparate_imp\n",
    "        scenario['white_pois_y_pred'] = white_pois_y_pred\n",
    "        scenario['white_pois_acc'] = white_pois_acc\n",
    "        scenario['white_pois_FNR'] = white_pois_FNR\n",
    "        scenario['white_pois_FPR'] = white_pois_FPR\n",
    "        scenario['white_odds'] = white_odds_diff\n",
    "\n",
    "\n",
    "\n",
    "        ########################\n",
    "        ### BLACK BOX ATTACK ###\n",
    "        ########################\n",
    "        real_model, real_acc = train_SVM(scenario[\"training\"], scenario[\"test\"])\n",
    "\n",
    "        surrogate_clf = deepcopy(original_model)\n",
    "\n",
    "        black_pois_points, black_pois_tr = execute_adversarial_attack(surrogate_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"], perc_pois)\n",
    "        ##Â Retraining with poisoned points\n",
    "\n",
    "        black_pois_clf = deepcopy(real_model)\n",
    "        black_pois_clf = black_pois_clf.fit(black_pois_tr)\n",
    "        black_pois_y_pred = black_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "        black_pois_acc = metric.performance_score(y_true=scenario[\"test\"].Y, y_pred=black_pois_y_pred)\n",
    "        black_pois_disparate_imp = calculate_disparate_impact(black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        black_pois_FNR, black_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        black_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "\n",
    "        scenario['black_poisoned_classifier'] = black_pois_clf\n",
    "        scenario['black_poisoned_points'] = black_pois_points\n",
    "        scenario['black_pois_d_imp'] = black_pois_disparate_imp\n",
    "        scenario['black_pois_y_pred'] = black_pois_y_pred\n",
    "        scenario['black_pois_acc'] = black_pois_acc\n",
    "        scenario['black_pois_FNR'] = black_pois_FNR\n",
    "        scenario['black_pois_FPR'] = black_pois_FPR\n",
    "        scenario['black_odds'] = black_odds_diff\n",
    "\n",
    "        ################################\n",
    "        ### CLASSIC POISONING ATTACK ###\n",
    "        ################################\n",
    "        normal_pois_clf = deepcopy(original_model)\n",
    "\n",
    "        privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "        privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "\n",
    "\n",
    "        normal_pois_points, normal_pois_tr = execute_normal_poisoning_attack(normal_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"], perc_pois)\n",
    "        ##Â Retraining with poisoned points\n",
    "        normal_pois_clf = normal_pois_clf.fit(normal_pois_tr)\n",
    "        normal_pois_y_pred = normal_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "        metric = CMetricAccuracy()\n",
    "        normal_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=normal_pois_y_pred)\n",
    "        print(\"->> normal\")\n",
    "        normal_pois_disparate_imp = calculate_disparate_impact(normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "        normal_pois_FNR, normal_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "        normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "        scenario['normal_poisoned_classifier'] = normal_pois_clf\n",
    "        scenario['normal_poisoned_points'] = normal_pois_points\n",
    "        scenario['normal_pois_d_imp'] = normal_pois_disparate_imp\n",
    "        scenario['normal_odds'] = normal_odds_diff\n",
    "        scenario['normal_pois_y_pred'] = normal_pois_y_pred\n",
    "        scenario['normal_pois_acc'] = normal_pois_acc\n",
    "        scenario['normal_pois_FNR'] = normal_pois_FNR\n",
    "        scenario['normal_pois_FPR'] = normal_pois_FPR\n",
    "        scenario['normal_odds'] = normal_odds_diff\n",
    "\n",
    "\n",
    "        scenarios2.append(scenario)\n",
    "    _results.append(scenarios2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "def plot_use_case_multiple_runs(scenarios, data_dimp=None , n_scenarios=5, title=None):\n",
    "    \n",
    "    _x_ = RANGE\n",
    "    \n",
    "    fig=plt.figure(figsize=[12,8])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(2,4) # 2 rows, 3 columns\n",
    "\n",
    "    ax1=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "    ax1.plot(_x_,[float(UC[\"original_acc\"]) for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax1.plot(_x_,[float(UC[\"white_pois_acc\"]) for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax1.plot(_x_,[float(UC[\"black_pois_acc\"]) for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax1.plot(_x_,[float(UC[\"normal_pois_acc\"]) for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    \n",
    "\n",
    "    ax2=fig.add_subplot(gs[0,2]) # First row, first column\n",
    "    ax2.set_title(\"Demographic parity\")\n",
    "    ax2.plot(_x_,[UC[\"orig_d_imp\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #if data_dimp is not None:\n",
    "    #    ax2.plot(_x_,data_dimp, c=\"darkgrey\", label=\"Original data\")\n",
    "    ax2.plot(_x_,[UC[\"white_pois_d_imp\"] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2.plot(_x_,[UC[\"black_pois_d_imp\"] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax2.plot(_x_,[UC[\"normal_pois_d_imp\"] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    #ax2.legend(bbox_to_anchor=(1.1, -0.1),fontsize=15)\n",
    "    \n",
    "    ax2b=fig.add_subplot(gs[0,3]) # First row, first column\n",
    "    ax2b.set_title(\"Average odds difference\")\n",
    "    ax2b.plot(_x_,[UC[\"orig_odds\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax2b.plot(_x_,[UC[\"white_odds\"] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2b.plot(_x_,[UC[\"black_odds\"] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax2b.plot(_x_,[UC[\"normal_odds\"] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    \n",
    "    ax3=fig.add_subplot(gs[1,0]) # First row, second column\n",
    "    ax3.set_title(\"FNR privileged\")\n",
    "    ax3.plot(_x_,[UC[\"orig_FNR\"][\"FNR_privileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax3.plot(_x_,[UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax3.plot(_x_,[UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax3.plot(_x_,[UC[\"normal_pois_FNR\"]['FNR_privileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "\n",
    "    ax4=fig.add_subplot(gs[1,1]) # First row, third column\n",
    "    ax4.set_title(\"FNR unprivileged\")\n",
    "    ax4.plot(_x_,[UC[\"orig_FNR\"][\"FNR_unprivileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax4.plot(_x_,[UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax4.plot(_x_,[UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax4.plot(_x_,[UC[\"normal_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    #ax4.plot([], [], c=\"gray\", label=\"Disparate impact in the data\")\n",
    "    \n",
    "    ax4.legend(bbox_to_anchor=(1.8, -0.1),fontsize=15)\n",
    "    \n",
    "    ax5=fig.add_subplot(gs[1,2]) # First row, second column\n",
    "    ax5.set_title(\"FPR privileged\")\n",
    "    ax5.plot(_x_,[UC[\"orig_FPR\"][\"FPR_privileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax5.plot(_x_,[UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax5.plot(_x_,[UC[\"black_pois_FPR\"]['FPR_privileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax5.plot(_x_,[UC[\"normal_pois_FPR\"]['FPR_privileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "\n",
    "    ax6=fig.add_subplot(gs[1,3]) # First row, third column\n",
    "    ax6.set_title(\"FPR unprivileged\")\n",
    "    ax6.plot(_x_,[UC[\"orig_FPR\"][\"FPR_unprivileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax6.plot(_x_,[UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax6.plot(_x_,[UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax6.plot(_x_,[UC[\"normal_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], '--', c=\"blue\", label=\"Classic poisoning attack\")\n",
    "    \n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_use_case_multiple_runs(scenarios2, dimp_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenarios2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using different algorithms as black box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_models(X,y, X_test, y_test, sentitive_att_test):\n",
    "    m1 = DecisionTreeClassifier().fit(X, y)\n",
    "    m2 = RandomForestClassifier().fit(X, y)\n",
    "    m3 = LogisticRegression(random_state=0).fit(X, y)\n",
    "    m4 = SVC(kernel='linear').fit(X, y)\n",
    "    m5 = GaussianNB().fit(X, y)\n",
    "    #m6 = KNeighborsClassifier().fit(X, y)\n",
    "    m7 = SVC(gamma='auto', kernel='rbf').fit(X,y)\n",
    "    \n",
    "    ms = [m1,m2,m3,m4,m5,m7]\n",
    "\n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    for m in ms:\n",
    "        _preds = m.predict(X_test)\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sentitive_att_test))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sentitive_att_test))\n",
    "\n",
    "    return accs,dimp,avg_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        tr2 = tr.deepcopy().append(ps)\n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        for z in range(3):\n",
    "            t.append(train_models(tr2.X.get_data(), tr2.Y.get_data(), ts.X.get_data(), ts.Y.get_data(), sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    _tmp.append((accs_means, dimp_means, odds_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "\n",
    "models = [\"DecisionTree\", \"RandomForest\", \"LogReg\", \"Linear SVM\", \"GaussianNB\", \"RBF SVM\"]\n",
    "model_cs = ['b', 'g', 'k', 'r', 'm', 'k']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[16,4])\n",
    "ax=fig.add_subplot(131)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    ax.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax.set_xlabel(\"% of poisoned samples\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(132)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax2.set_xlabel(\"% of poisoned samples\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(133)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax3.set_xlabel(\"% of poisoned samples\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    "ax2.legend(bbox_to_anchor=(1.4, -.2), fontsize=15, ncol=3)\n",
    "fig.suptitle(\"Performance of transfer attacks\", x=0.5, y=1.1, fontsize=18)\n",
    "plt.show()\n",
    "fig.savefig(\"attack_compas_data_transf.eps\", format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models2(ms, black_model, train_set, black_train_set, test_set, sensitive_att):\n",
    "    \n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    y_test = test_set.Y.get_data()\n",
    "    \n",
    "    for m in ms:\n",
    "        #m = m.fit(train_set)\n",
    "        _preds = m.predict(test_set.X).get_data()\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sensitive_att))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sensitive_att))\n",
    "\n",
    "\n",
    "    black_model = black_model.fit(black_train_set)   \n",
    "    _preds2 = black_model.predict(test_set.X).get_data()\n",
    "    \n",
    "    accs.append(accuracy_score(y_test, _preds2))\n",
    "    dimp.append(calculate_disparate_impact(_preds2, sensitive_att))\n",
    "    avg_odds.append(get_average_odds_difference(y_test, _preds2, sensitive_att))    \n",
    "\n",
    "    return accs,dimp,avg_odds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "dimps = []\n",
    "odds_means = []\n",
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        ps2 = sc['black_poisoned_points']\n",
    "        \n",
    "        m1 = sc['original_classifier']\n",
    "        m2 = sc['white_poisoned_classifier']\n",
    "        black_m = sc['black_poisoned_classifier']\n",
    "        m4 = sc['normal_poisoned_classifier']\n",
    "        ms = [m1,m2,m4]\n",
    "        \n",
    "        tr = tr.deepcopy().append(ps)\n",
    "        tr2 = tr.deepcopy().append(ps2)\n",
    "        \n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        \n",
    "        #for z in range(3):\n",
    "        t.append(train_models2(ms, black_m, tr, tr2, ts, sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    _tmp.append((accs_means, dimp_means, odds_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "\n",
    "models = [\"Original model\", \"White-box attack\", \"Error-generic poisoning attack\", \"Black-box attack\"]\n",
    "model_cs = ['g', 'r', 'b', 'orange']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[16,4])\n",
    "ax=fig.add_subplot(131)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    ax.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax.set_xlabel(\"% of poisoned samples\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(132)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax2.set_xlabel(\"% of poisoned samples\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(133)\n",
    "\n",
    "_x_ = RANGE\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "ax3.set_xlabel(\"% of poisoned samples\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    " \n",
    "ax2.legend(bbox_to_anchor=(2, -.2), fontsize=15, ncol=4)\n",
    "fig.suptitle(\"Performance of attacks on COMPAS data\", x=0.5, y=1.1)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"attack_compas_data3.eps\", format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models2(ms, black_model, train_set, black_train_set, test_set, sensitive_att):\n",
    "    \n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    fpr_priv = []\n",
    "    fpr_unpriv = []\n",
    "    fnr_priv = []\n",
    "    fnr_unpriv = []\n",
    "    \n",
    "    y_test = test_set.Y.get_data()\n",
    "    \n",
    "    for m in ms:\n",
    "        #m = m.fit(train_set)\n",
    "        _preds = m.predict(test_set.X).get_data()\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sensitive_att))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sensitive_att))\n",
    "        \n",
    "        errors = get_error_rates(y_test, _preds, sensitive_att)\n",
    "        \n",
    "        fnr_priv.append(errors[0]['FNR_privileged'])\n",
    "        fnr_unpriv.append(errors[0]['FNR_unprivileged'])\n",
    "        \n",
    "        fpr_priv.append(errors[1]['FPR_privileged'])\n",
    "        fpr_unpriv.append(errors[1]['FPR_unprivileged'])\n",
    "\n",
    "    #black_model = black_model.fit(black_train_set)   \n",
    "    _preds2 = black_model.predict(test_set.X).get_data()\n",
    "    \n",
    "    accs.append(accuracy_score(y_test, _preds2))\n",
    "    dimp.append(calculate_disparate_impact(_preds2, sensitive_att))\n",
    "    avg_odds.append(get_average_odds_difference(y_test, _preds2, sensitive_att))  \n",
    "    errors = get_error_rates(y_test, _preds2, sensitive_att)\n",
    "        \n",
    "    fnr_priv.append(errors[0]['FNR_privileged'])\n",
    "    fnr_unpriv.append(errors[0]['FNR_unprivileged'])\n",
    "\n",
    "    fpr_priv.append(errors[1]['FPR_privileged'])\n",
    "    fpr_unpriv.append(errors[1]['FPR_unprivileged'])\n",
    "\n",
    "    return accs,dimp,avg_odds, fnr_priv, fnr_unpriv, fpr_priv, fpr_unpriv\n",
    "    \n",
    "accs = []\n",
    "dimps = []\n",
    "odds_means = []\n",
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        ps2 = sc['black_poisoned_points']\n",
    "        \n",
    "        m1 = sc['original_classifier']\n",
    "        m2 = sc['white_poisoned_classifier']\n",
    "        black_m = sc['black_poisoned_classifier']\n",
    "        m4 = sc['normal_poisoned_classifier']\n",
    "        ms = [m1,m2,m4]\n",
    "        \n",
    "        tr = tr.deepcopy().append(ps)\n",
    "        tr2 = tr.deepcopy().append(ps2)\n",
    "        \n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        \n",
    "        for z in range(3):\n",
    "            t.append(train_models2(ms, black_m, tr, tr2, ts, sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "    fnr_priv = [c[3] for c in t] \n",
    "    fnr_unpriv = [c[4] for c in t]\n",
    "    fpr_priv = [c[5] for c in t]\n",
    "    fpr_unpriv = [c[6] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    fnr_p_means = np.array(fnr_priv).mean(0)\n",
    "    fnr_u_means = np.array(fnr_unpriv).mean(0)\n",
    "    fpr_p_means = np.array(fpr_priv).mean(0)\n",
    "    fpr_u_means = np.array(fpr_unpriv).mean(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    _tmp.append((accs_means, dimp_means, odds_means,fnr_p_means,fnr_u_means,fpr_p_means,fpr_u_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "fnr_priv = [c[3] for c in _tmp] \n",
    "fnr_unpriv = [c[4] for c in _tmp]\n",
    "fpr_priv = [c[5] for c in _tmp]\n",
    "fpr_unpriv = [c[6] for c in _tmp]\n",
    "\n",
    "models = [\"Original model\", \"White-box attack\", \"Error-generic poisoning attack\", \"Black-box attack\"]\n",
    "model_cs = ['g', 'r', 'b', 'orange']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[16,8])\n",
    "\n",
    "gs=GridSpec(2,4) # 2 rows, 4 columns\n",
    "\n",
    "ax=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    c = model_cs[i]\n",
    "    mark = model_ms[i]\n",
    "    l = models[i]\n",
    "    ax.plot(_x_,t,c=c,marker=mark,ls=':',label=l)\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax.set_xlabel(\"Euclidean distance in data\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(gs[0,2]) # Second row, span all columns\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax2.set_xlabel(\"Euclidean distance\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(gs[0,3])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax3.set_xlabel(\"Euclidean distance\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    "\n",
    "ax4=fig.add_subplot(gs[1,0])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fnr_p[i] for fnr_p in fnr_priv]\n",
    "    ax4.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax4.set_xlabel(\"Euclidean distance\")\n",
    "ax4.set_title(\"FNR privileged\")\n",
    "\n",
    "ax5=fig.add_subplot(gs[1,1])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fnr_up[i] for fnr_up in fnr_unpriv]\n",
    "    ax5.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax5.set_xlabel(\"Euclidean distance\")\n",
    "ax5.set_title(\"FNR unprivileged\")\n",
    "\n",
    "ax6=fig.add_subplot(gs[1,2])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fpr_p[i] for fpr_p in fpr_priv]\n",
    "    ax6.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax6.set_xlabel(\"Euclidean distance\")\n",
    "ax6.set_title(\"FPR privileged\")\n",
    "\n",
    "ax7=fig.add_subplot(gs[1,3])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fpr_up[i] for fpr_up in fpr_unpriv]\n",
    "    ax7.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax7.set_xlabel(\"Euclidean distance\")\n",
    "ax7.set_title(\"FPR unprivileged\")\n",
    "\n",
    " \n",
    "ax6.legend(bbox_to_anchor=(0.5, -.2), fontsize=15)\n",
    "fig.suptitle(\"Performance of attacks on synthetic data\", x=0.5, y=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.align_labels() \n",
    "plt.show()\n",
    "fig.savefig(\"attack_compas_data2.eps\", format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrics = [accs,dimps,odds,fnr_priv,fnr_unpriv,fpr_priv,fpr_unpriv]\n",
    "_metric_names = [\"Accuracy\", \"Demographic parity\", \"Average odds difference\", \"FNR priv\", \"FNR unpriv\", \"FPR priv\", \"FPR unpriv\"]\n",
    "for m_idx, m in enumerate(_metrics):\n",
    "    m = np.array(m)\n",
    "    if m_idx != 3:\n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" Generic/Orig: {}\".format(np.mean(m[:,2]/m[:,0])))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,3]/m[:,0])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,1]/m[:,0])))\n",
    "    else:        \n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" Generic/Orig: {}\".format(np.mean(m[:,2][:-1] / m[:,0][:-1])))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,3][:-1] / m[:,0][:-1])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,1][:-1] / m[:,0][:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
