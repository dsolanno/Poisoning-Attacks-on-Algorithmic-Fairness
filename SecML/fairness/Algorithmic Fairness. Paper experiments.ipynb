{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import warnings\n",
    "from scipy import integrate\n",
    "\n",
    "from scipy import stats\n",
    "random_state = 999\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "## General importsÇ\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "## SKLearn imports\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "## AIF360 imports\n",
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "\n",
    "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
    "            import load_preproc_data_adult, load_preproc_data_german, load_preproc_data_compas\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions\\\n",
    "            import get_distortion_adult, get_distortion_german, get_distortion_compas\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "\n",
    "\n",
    "#SEC_ML imports\n",
    "from secml.data.c_dataset import CDataset\n",
    "from secml.ml.classifiers import CClassifierSVM, CClassifierLogistic\n",
    "from secml.ml.kernels import CKernelRBF, CKernelLinear\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "from secml.data.splitter import CDataSplitterKFold\n",
    "\n",
    "# Poisoning attacks\n",
    "from secml.adv.attacks import CAttackPoisoningSVM\n",
    "from secml.adv.attacks.poisoning.c_attack_poisoning_logistic_regression import CAttackPoisoningLogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x72 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAABQCAYAAADySAbpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA3FJREFUeJzt2z+LXGUAxeGT7MbsYpCwCHFlQQs7C6ugQrZRwUqrICQfQuysFNHKTku/QAIiNqlCgk0WjKSyFQuFxRWRECRhTDbrWPgH0s0Oe3nD4XmaO8W8zJnm3h8Dc2w+nwcAAFocHz0AAACOksAFAKCKwAUAoIrABQCgisAFAKCKwAUAoIrABQCgisAFAKCKwAUAoIrABQCgyuoSZ04mOZtkL8nB0c4BAID/rSTZTHIryf1FDy0TuGeT3FjiHAAALGM7yc6ib14mcPeS5NoPv2W23/kD7tsvbubcp9+MnjGZnfdfy/XdL0bPmMTnN7/OlfNX89ZXb46eMokr56/m4eVLo2dMZvXCxey9/OroGZPZ/O7b/HXz49EzJnP8lQ+Tz54fPWM67/2U76//OHrFJF5644V88M7l0TMm88mXF5L03juTi7n27uujR0xibeNMtj+6lPzbn4taJnAPkmS2f5B7DzoDN0l278xGT5jU7OEfoydMYu/eL49cK929O3rBpA52d0dPmNaft0cvmNadn0cvmNSD2f7oCZO5/Wv3vSXp/n6z34ufe/84VHT6kxkAAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVBC4AAFUELgAAVQQuAABVVpc4s5Ik6ydWjnjK42Xr9ProCZNaX31q9IRJbD757CPXSqdOjV4wqZWtrdETprW2MXrBtE4/N3rBpJ5YPzF6wmQ2num+tyTd32/96c7n3trGmf9eHio8j83n88N+1rkkNw57CAAAlrSdZGfRNy8TuCeTnE2yl+TgsIcBAGBBK0k2k9xKcn/RQ8sELgAAPLb8yQwAgCoCFwCAKgIXAIAqAhcAgCoCFwCAKgIXAIAqAhcAgCoCFwCAKgIXAIAqAhcAgCp/A65JaH/JHWjgAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_palette=sns.diverging_palette(255, 133, l=60, n=12, center=\"dark\")\n",
    "sns.palplot(sns.color_palette(\"Paired\", 12))\n",
    "sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"paper\", rc={\"font.size\":16,\"axes.titlesize\":20,\"axes.labelsize\":16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # for plotting stuff\n",
    "from random import seed, shuffle\n",
    "from scipy.stats import multivariate_normal # generating synthetic data\n",
    "SEED = 999\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def generate_synthetic_data(plot_data=False, distrib_distance=np.array([5,5]), ax=None, title=\"\"):\n",
    "\n",
    "    \"\"\"\n",
    "        Code for generating the synthetic data.\n",
    "        We will have two non-sensitive features and one sensitive feature.\n",
    "        A sensitive feature value of 0.0 means the example is considered to be in protected group (e.g., female) and 1.0 means it's in non-protected group (e.g., male).\n",
    "    \"\"\"\n",
    "\n",
    "    n_samples = 400 # generate these many data points per class\n",
    "    disc_factor = math.pi / 4.0 # this variable determines the initial discrimination in the data -- decraese it to generate more discrimination\n",
    "\n",
    "    def gen_gaussian(mean_in, cov_in, class_label):\n",
    "        nv = multivariate_normal(mean = mean_in, cov = cov_in)\n",
    "        X = nv.rvs(n_samples)\n",
    "        y = np.ones(n_samples, dtype=float) * class_label\n",
    "        return nv,X,y\n",
    "\n",
    "    \"\"\" Generate the non-sensitive features randomly \"\"\"\n",
    "    # We will generate one gaussian cluster for each class\n",
    "    mu1, sigma1 = np.array([2, 2]), [[5, 1], [1, 5]]\n",
    "    mu2, sigma2 = np.array(mu1-distrib_distance), [[10, 1], [1, 3]]\n",
    "    nv1, X1, y1 = gen_gaussian(mu1, sigma1, 1) # positive class\n",
    "    nv2, X2, y2 = gen_gaussian(mu2, sigma2, 0) # negative class\n",
    "\n",
    "    # join the posisitve and negative class clusters\n",
    "    X = np.vstack((X1, X2))\n",
    "    y = np.hstack((y1, y2))\n",
    "\n",
    "    # shuffle the data\n",
    "    perm = list(range(0,n_samples*2))\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    \n",
    "    rotation_mult = np.array([[math.cos(disc_factor), -math.sin(disc_factor)], [math.sin(disc_factor), math.cos(disc_factor)]])\n",
    "    X_aux = np.dot(X, rotation_mult)\n",
    "\n",
    "\n",
    "    \"\"\" Generate the sensitive feature here \"\"\"\n",
    "    x_control = [] # this array holds the sensitive feature value\n",
    "    for i in range (0, len(X)):\n",
    "        x = X_aux[i]\n",
    "\n",
    "        # probability for each cluster that the point belongs to it\n",
    "        p1 = nv1.pdf(x)\n",
    "        p2 = nv2.pdf(x)\n",
    "        \n",
    "        # normalize the probabilities from 0 to 1\n",
    "        s = p1+p2\n",
    "        p1 = p1/s\n",
    "        p2 = p2/s\n",
    "        \n",
    "        r = np.random.uniform() # generate a random number from 0 to 1\n",
    "\n",
    "        if r < p1: # the first cluster is the positive class\n",
    "            x_control.append(1.0) # 1.0 means its male\n",
    "        else:\n",
    "            x_control.append(0.0) # 0.0 -> female\n",
    "\n",
    "    x_control = np.array(x_control)\n",
    "\n",
    "    \"\"\" Show the data \"\"\"\n",
    "    if plot_data:\n",
    "        num_to_draw = 200 # we will only draw a small number of points to avoid clutter\n",
    "        x_draw = X[:num_to_draw]\n",
    "        y_draw = y[:num_to_draw]\n",
    "        x_control_draw = x_control[:num_to_draw]\n",
    "\n",
    "        X_s_0 = x_draw[x_control_draw == 0.0]\n",
    "        X_s_1 = x_draw[x_control_draw == 1.0]\n",
    "        y_s_0 = y_draw[x_control_draw == 0.0]\n",
    "        y_s_1 = y_draw[x_control_draw == 1.0]\n",
    "        \n",
    "        \n",
    "        if ax is not None:\n",
    "            ax.scatter(X_s_0[y_s_0==1.0][:, 0], X_s_0[y_s_0==1.0][:, 1], color='green', marker='x', s=30, linewidth=1.5, label= \"Unprivileged favorable\")\n",
    "            ax.scatter(X_s_0[y_s_0==0.0][:, 0], X_s_0[y_s_0==0.0][:, 1], color='red', marker='x', s=30, linewidth=1.5, label = \"Unprivileged unfavorable\")\n",
    "            ax.scatter(X_s_1[y_s_1==1.0][:, 0], X_s_1[y_s_1==1.0][:, 1], color='green', marker='o', facecolors='none', s=30, label = \"Privileged favorable\")\n",
    "            ax.scatter(X_s_1[y_s_1==0.0][:, 0], X_s_1[y_s_1==0.0][:, 1], color='red', marker='o', facecolors='none', s=30, label = \"Privileged unfavorable\")\n",
    "\n",
    "\n",
    "            ax.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off') # dont need the ticks to see the data distribution\n",
    "            ax.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "            #plt.legend(loc=2, fontsize=15)\n",
    "            ax.set_title(title)\n",
    "            \n",
    "            #plt.xlim((-15,10))\n",
    "            #plt.ylim((-10,15))\n",
    "            #plt.savefig(\"img/data.png\")\n",
    "            #plt.show()\n",
    "        else:\n",
    "            plt.scatter(X_s_0[y_s_0==1.0][:, 0], X_s_0[y_s_0==1.0][:, 1], color='green', marker='x', s=30, linewidth=1.5, label= \"Unprivileged favorable\")\n",
    "            plt.scatter(X_s_0[y_s_0==0.0][:, 0], X_s_0[y_s_0==0.0][:, 1], color='red', marker='x', s=30, linewidth=1.5, label = \"Unprivileged unfavorable\")\n",
    "            plt.scatter(X_s_1[y_s_1==1.0][:, 0], X_s_1[y_s_1==1.0][:, 1], color='green', marker='o', facecolors='none', s=30, label = \"Privileged favorable\")\n",
    "            plt.scatter(X_s_1[y_s_1==0.0][:, 0], X_s_1[y_s_1==0.0][:, 1], color='red', marker='o', facecolors='none', s=30, label = \"Privileged unfavorable\")\n",
    "\n",
    "\n",
    "            plt.tick_params(axis='x', which='both', bottom='off', top='off', labelbottom='off') # dont need the ticks to see the data distribution\n",
    "            plt.tick_params(axis='y', which='both', left='off', right='off', labelleft='off')\n",
    "            #plt.legend(loc=2, fontsize=15)\n",
    "\n",
    "            plt.legend(bbox_to_anchor=(1.01, 1.05),fontsize=15)\n",
    "            #plt.xlim((-15,10))\n",
    "            #plt.ylim((-10,15))\n",
    "            #plt.savefig(\"img/data.png\")\n",
    "            plt.show()\n",
    "\n",
    "    x_control = {\"s1\": x_control} # all the sensitive features are stored in a dictionary\n",
    "    return X,y,x_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Creating custom Weighted CLoss to solve the optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from secml.ml.classifiers.loss import CLossClassification, CLossLogistic\n",
    "from secml.array import CArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class CLossDisparateImpact(CLossClassification):\n",
    "    \"\"\"Surrogate function of disparate impact.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    class_type : 'log'\n",
    "    suitable_for : 'classification'\n",
    "\n",
    "    \"\"\"\n",
    "    __class_type = 'dimp_log'\n",
    "\n",
    "    def __init__(self, _privileged_condition):\n",
    "        self._privileged_condition = CArray(_privileged_condition)\n",
    "\n",
    "    def unprivileged(self):\n",
    "        \"\"\"Give 1 to unprivileged, 0 to privileged\"\"\"\n",
    "        y = CArray.zeros(self._privileged_condition.size)\n",
    "        y[self._privileged_condition == 0] = 1\n",
    "        return y\n",
    "\n",
    "    def loss(self, y_true, score, pos_label=1):\n",
    "        \"\"\"Computes loss_priv-loss_unpriv, which is what we aim to max\"\"\"\n",
    "        # give 1 to unpriv, 0 to priv\n",
    "        y = self.unprivileged()\n",
    "        p_priv = (y == 0).sum() / y.size\n",
    "        p_unpriv = (y == 1).sum() / y.size\n",
    "        # loss = (score >= 0) != y  # zero-one loss\n",
    "        loss = CLossLogistic().loss(y_true=y, score=score)  # smoothed version\n",
    "        loss[y == 1] *= -p_priv / p_unpriv  # rebalance class weights\n",
    "        return loss\n",
    "\n",
    "    def dloss(self, y_true, score, pos_label=1):\n",
    "        \"\"\"Computes the derivative of the loss vs score.\"\"\"\n",
    "        y = self.unprivileged()\n",
    "        p_priv = (y == 0).sum() / y.size\n",
    "        p_unpriv = (y == 1).sum() / y.size\n",
    "        grad = CLossLogistic().dloss(y, score, pos_label)\n",
    "        grad[y == 1] *= -p_priv / p_unpriv  # rebalance class weights\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_disparate_impact(y,sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=True):\n",
    "    \n",
    "    privileged = y[sensible_att_vals == privileged_classes]\n",
    "    unprivileged = y[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    unprivileged_favorable = unprivileged[unprivileged==favorable_output]\n",
    "    privileged_favorable = privileged[privileged==favorable_output]\n",
    "    \n",
    "    n1 =  (len(unprivileged_favorable)/ len(unprivileged))\n",
    "    n2 = (len(privileged_favorable)/ len(privileged))\n",
    "    disparate_impact = n1 - n2#/ (max(n2,0.0001)) \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tUnprivileged favorable1: \", n1)\n",
    "        print(\"\\tPrivileged favorable2: \", n2)\n",
    "        print(\"DIMP: \", disparate_impact)\n",
    "     \n",
    "    \n",
    "    return disparate_impact\n",
    "\n",
    "def calculate_error_rate_ratio(y_true, y_pred,sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=True):\n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_num_errors = len(privileged_y_true) - (len(np.where(np.isclose(privileged_y_true, privileged_y_pred))[0]))\n",
    "    unprivileged_num_errors = len(unprivileged_y_true) - (len(np.where(np.isclose(unprivileged_y_true, unprivileged_y_pred))[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tN1: \", n1)\n",
    "        print(\"\\tN2: \", n2)\n",
    "        \n",
    "    \n",
    "        \n",
    "    error_rate = (unprivileged_num_errors / len(unprivileged_y_true)) / (privileged_num_errors / len(privileged_y_true))\n",
    "    return error_rate\n",
    "    \n",
    "#12[(𝐹𝑃𝑅𝐷=unprivileged−𝐹𝑃𝑅𝐷=privileged)+(𝑇𝑃𝑅𝐷=unprivileged−𝑇𝑃𝑅𝐷=privileged))]\n",
    "def get_average_odds_difference(y_true, y_pred, sensible_att_vals, privileged_classes=1, favorable_output=1):\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)    \n",
    "\n",
    "    sensible_att_vals = np.array(sensible_att_vals)\n",
    "                                 \n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "                                 \n",
    "                                 \n",
    "    FPR_unprivileged = get_false_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    FPR_privileged = get_false_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    TPR_unprivileged = get_true_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    TPR_privileged = get_true_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "                              \n",
    "    return 0.5 * ((FPR_unprivileged - FPR_privileged) + (TPR_unprivileged - TPR_privileged))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def get_false_positive_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp1 = y_pred[y_true!=favorable_output]\n",
    "    fp = _tmp1[_tmp1 == favorable_output]\n",
    "    \n",
    "    N = len(y_true[y_true != favorable_output])\n",
    "    \n",
    "    if N == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fp) / N\n",
    "\n",
    "def get_true_positive_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp1 = y_pred[y_true==favorable_output]\n",
    "    fp = _tmp1[_tmp1 == favorable_output]\n",
    "    \n",
    "    P = len(y_true[y_true == favorable_output])\n",
    "    \n",
    "    if N == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fp) / P\n",
    "    \n",
    "    \n",
    "def get_false_negative_rate(y_true, y_pred, favorable_output):\n",
    "    _tmp = y_pred[y_true==favorable_output]\n",
    "    \n",
    "    fn = _tmp[_tmp != favorable_output]\n",
    "    \n",
    "    if len(_tmp) == 0:\n",
    "        return 0\n",
    "    \n",
    "    return len(fn) / len(_tmp)\n",
    "\n",
    "def get_error_rates(y_true, y_pred, sensible_att_vals, privileged_classes=1, favorable_output=1, verbose=False):\n",
    "    privileged_y_true = y_true[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_true = y_true[sensible_att_vals != privileged_classes]\n",
    "    \n",
    "    privileged_y_pred = y_pred[sensible_att_vals == privileged_classes]\n",
    "    unprivileged_y_pred = y_pred[sensible_att_vals != privileged_classes]\n",
    "    \"\"\"\n",
    "    privileged_num_errors = len(privileged_y_true) - (len(np.where(np.isclose(privileged_y_true, privileged_y_pred))[0]))\n",
    "    unprivileged_num_errors = len(unprivileged_y_true) - (len(np.where(np.isclose(unprivileged_y_true, unprivileged_y_pred))[0]))\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tN1: \", n1)\n",
    "        print(\"\\tN2: \", n2)\n",
    "\n",
    "        error_rate = (unprivileged_num_errors / len(unprivileged_y_true)) / (privileged_num_errors / len(privileged_y_true))\n",
    "    \"\"\"\n",
    "    \n",
    "    FNR_privileged = get_false_negative_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    FNR_unprivileged = get_false_negative_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    \n",
    "    FPR_privileged = get_false_positive_rate(privileged_y_true, privileged_y_pred, favorable_output)\n",
    "    FPR_unprivileged = get_false_positive_rate(unprivileged_y_true, unprivileged_y_pred, favorable_output)\n",
    "    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\tFNR_1: \", FNR_privileged)\n",
    "        print(\"\\tFNR_2: \", FNR_unprivileged)\n",
    "        print(\"\\tFPR_1: \", FPR_privileged)\n",
    "        print(\"\\tFPR_2: \", FPR_unprivileged)\n",
    "    \n",
    "    FNR = -1\n",
    "    FPR = -1\n",
    "    \n",
    "    try:\n",
    "        FNR = FNR_unprivileged / FNR_privileged\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        FPR = FPR_unprivileged / FPR_privileged\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "\n",
    "    return ({\"FNR\": FNR, \"FNR_privileged\":FNR_privileged, \"FNR_unprivileged\":FNR_unprivileged, \"FNR\": 1}, {\"FPR\":FPR, \"FPR_privileged\":FPR_privileged, \"FPR_unprivileged\":FPR_unprivileged})\n",
    "\n",
    "\n",
    "\n",
    "def train_LogReg(training_set, test_set):\n",
    "\n",
    "    \n",
    "    # Metric to use for training and performance evaluation\n",
    "    # Creation of the multiclass classifier\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    #clf = CClassifierSVM(kernel=CKernelRBF()) # Radial Basis Function (RBF) kernel.\n",
    "    #clf = CClassifierSVM(kernel=CKernelLinear()) # Linear kernel.\n",
    "    clf = CClassifierLogistic()\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1, 10]}#, 'kernel.gamma': [0.1]}#, 5, 10, 25, 50, 100]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    \n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    print(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=training_set,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "\n",
    "    print(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    # We can now fit the classifier\n",
    "    clf.fit(training_set)\n",
    "    print(\"Training of classifier complete!\")\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(test_set.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=test_set.Y, y_pred=y_pred)\n",
    "\n",
    "    print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "    \n",
    "    return clf, acc\n",
    "\n",
    "def train_SVM(training_set, test_set):\n",
    "\n",
    "    \n",
    "    # Metric to use for training and performance evaluation\n",
    "    # Creation of the multiclass classifier\n",
    "    metric = CMetricAccuracy()\n",
    "\n",
    "    #clf = CClassifierSVM(kernel=CKernelRBF()) # Radial Basis Function (RBF) kernel.\n",
    "    clf = CClassifierSVM(kernel=CKernelLinear()) # Linear kernel.\n",
    "    #clf = CClassifierLogistic()\n",
    "    # Parameters for the Cross-Validation procedure\n",
    "    xval_params = {'C': [1, 10]}#,'kernel.gamma': [0.1, 5, 10, 25, 50, 100]}\n",
    "\n",
    "    # Let's create a 3-Fold data splitter\n",
    "    \n",
    "    xval_splitter = CDataSplitterKFold(num_folds=3, random_state=random_state)\n",
    "\n",
    "    # Select and set the best training parameters for the classifier\n",
    "    print(\"Estimating the best training parameters...\")\n",
    "    best_params = clf.estimate_parameters(\n",
    "        dataset=training_set,\n",
    "        parameters=xval_params,\n",
    "        splitter=xval_splitter,\n",
    "        metric='accuracy',\n",
    "        perf_evaluator='xval'\n",
    "    )\n",
    "\n",
    "    print(\"The best training parameters are: \", best_params)\n",
    "\n",
    "    # We can now fit the classifier\n",
    "    clf.fit(training_set)\n",
    "    print(\"Training of classifier complete!\")\n",
    "\n",
    "    # Compute predictions on a test set\n",
    "    y_pred = clf.predict(test_set.X)\n",
    "\n",
    "    # Evaluate the accuracy of the classifier\n",
    "    acc = metric.performance_score(y_true=test_set.Y, y_pred=y_pred)\n",
    "\n",
    "    print(\"Accuracy on test set: {:.2%}\".format(acc))\n",
    "    \n",
    "    return clf, acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def execute_adversarial_attack(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois=0.25):\n",
    "\n",
    "    metric = CMetricAccuracy()\n",
    "    NUM_SAMPLES_TRAIN = training_set.num_samples\n",
    "    n_poisoning_points = int(NUM_SAMPLES_TRAIN * percentage_pois) # Number of poisoning points to generate\n",
    "    print(\"Creating {} poisoning samples \".format(n_poisoning_points))\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.05,\n",
    "        'eta_min': 0.05,\n",
    "        'eta_max': None,\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-6\n",
    "    }\n",
    "\n",
    "\n",
    "    pois_attack = CAttackPoisoningLogisticRegression(classifier=surrogate_clf,\n",
    "                                      training_data=training_set,\n",
    "                                      surrogate_classifier=surrogate_clf,\n",
    "                                      surrogate_data=validation_set,\n",
    "                                      val=validation_set,\n",
    "                                      distance='l2',\n",
    "                                      dmax=40,\n",
    "                                      lb=validation_set.X.min(), ub=validation_set.X.max(),\n",
    "                                      solver_params=solver_params,\n",
    "                                      random_seed=random_state,\n",
    "                                      init_type=\"random\")\n",
    "\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "    \n",
    "    dimp_loss = CLossDisparateImpact(privileged_condition_validation)\n",
    "    pois_attack._attacker_loss = dimp_loss\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(test_set.X, test_set.Y)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    \n",
    "    pois_tr = training_set.deepcopy().append(pois_ds)  # Join the training set with the poisoning points\n",
    "   \n",
    "    return pois_ds, pois_tr\n",
    "\n",
    "def execute_normal_poisoning_attack(surrogate_clf, training_set, validation_set, test_set, sensible_att_in_test, privileged_condition_validation, percentage_pois=0.25):\n",
    "\n",
    "    metric = CMetricAccuracy()\n",
    "    NUM_SAMPLES_TRAIN = training_set.num_samples\n",
    "    n_poisoning_points = int(NUM_SAMPLES_TRAIN * percentage_pois) # Number of poisoning points to generate\n",
    "    print(\"Creating {} poisoning samples \".format(n_poisoning_points))\n",
    "    # Should be chosen depending on the optimization problem\n",
    "    solver_params = {\n",
    "        'eta': 0.05,\n",
    "        'eta_min': 0.05,\n",
    "        'eta_max': None,\n",
    "        'max_iter': 1000,\n",
    "        'eps': 1e-6\n",
    "    }\n",
    "\n",
    "\n",
    "    pois_attack = CAttackPoisoningLogisticRegression(classifier=surrogate_clf,\n",
    "                                      training_data=training_set,\n",
    "                                      surrogate_classifier=surrogate_clf,\n",
    "                                      surrogate_data=validation_set,\n",
    "                                      val=validation_set,\n",
    "                                      distance='l2',\n",
    "                                      dmax=40,\n",
    "                                      lb=validation_set.X.min(), ub=validation_set.X.max(),\n",
    "                                      solver_params=solver_params,\n",
    "                                      random_seed=random_state,\n",
    "                                      init_type=\"random\")\n",
    "\n",
    "    pois_attack.n_points = n_poisoning_points\n",
    "    \n",
    "    #dimp_loss = CLossDisparateImpact(privileged_condition_validation)\n",
    "    #pois_attack._attacker_loss = dimp_loss\n",
    "\n",
    "    # Run the poisoning attack\n",
    "    print(\"Attack started...\")\n",
    "    pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(test_set.X, test_set.Y)\n",
    "    print(\"Attack complete!\")\n",
    "\n",
    "    \n",
    "    pois_tr = training_set.deepcopy().append(pois_ds)  # Join the training set with the poisoning points\n",
    "   \n",
    "    return pois_ds, pois_tr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "## 4. Generate Disparate Impact scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\tUnprivileged favorable1:  0.47988505747126436\n",
      "\tPrivileged favorable2:  0.5154867256637168\n",
      "DIMP:  -0.03560166819245242\n",
      "\tUnprivileged favorable1:  0.49122807017543857\n",
      "\tPrivileged favorable2:  0.5087281795511222\n",
      "DIMP:  -0.01750010937568358\n",
      "\tUnprivileged favorable1:  0.5022321428571429\n",
      "\tPrivileged favorable2:  0.4971590909090909\n",
      "DIMP:  0.005073051948052021\n",
      "\tUnprivileged favorable1:  0.45695364238410596\n",
      "\tPrivileged favorable2:  0.5561959654178674\n",
      "DIMP:  -0.09924232303376146\n",
      "\tUnprivileged favorable1:  0.3978260869565217\n",
      "\tPrivileged favorable2:  0.638235294117647\n",
      "DIMP:  -0.2404092071611253\n",
      "\tUnprivileged favorable1:  0.3624733475479744\n",
      "\tPrivileged favorable2:  0.6948640483383686\n",
      "DIMP:  -0.3323907007903942\n",
      "\tUnprivileged favorable1:  0.32954545454545453\n",
      "\tPrivileged favorable2:  0.7083333333333334\n",
      "DIMP:  -0.37878787878787884\n",
      "\tUnprivileged favorable1:  0.27053140096618356\n",
      "\tPrivileged favorable2:  0.7461139896373057\n",
      "DIMP:  -0.47558258867112213\n",
      "\tUnprivileged favorable1:  0.2190721649484536\n",
      "\tPrivileged favorable2:  0.7645631067961165\n",
      "DIMP:  -0.5454909418476629\n",
      "\tUnprivileged favorable1:  0.13687150837988826\n",
      "\tPrivileged favorable2:  0.7941176470588235\n",
      "DIMP:  -0.6572461386789352\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "N=9 #Max euclidean distance between average of distributions\n",
    "\n",
    "dimp_in_data = []\n",
    "euc_distances = []\n",
    "dimp_scenarios = []\n",
    "\n",
    "RANGE = np.arange(0,10, 1) \n",
    "\n",
    "for n in RANGE:\n",
    "    \n",
    "    ## Generating data\n",
    "    euc_dist = n\n",
    "    i = np.sqrt((euc_dist**2)/2)\n",
    "    X,y,X_control = generate_synthetic_data(False, np.array([i,i]))\n",
    "    formatted_X=np.array([X[:,0], X[:,1], X_control['s1']]).T ## Concatenating X with sensible att\n",
    "    \n",
    "    sec_ml_dataset_all = CDataset(X, y)\n",
    "    sensible_att_all = X_control['s1']\n",
    "    \n",
    "    euc_distances.append(n)\n",
    "    dimp_in_data.append(calculate_disparate_impact(sec_ml_dataset_all.Y.get_data(), sensible_att_all)) \n",
    "    \n",
    "    ## Splitting data. \n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(formatted_X, y, test_size=0.2, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    training = CDataset(X_train[:,:2], y_train)\n",
    "    training_sensible_att = X_train[:,2]\n",
    "    \n",
    "    validation = CDataset(X_val[:,:2], y_val)\n",
    "    validation_sensible_att = X_val[:,2]\n",
    "    val_lambda = np.zeros(validation.num_samples)\n",
    "    \n",
    "    ## Creating lambda vector\n",
    "    val_lambda[np.where((validation_sensible_att==0) & (y_val==0))[0]] == 1 ## Unprivileged denied\n",
    "    val_lambda[np.where((validation_sensible_att==0) & (y_val==1))[0]] == 1 ## Unprivileged granted\n",
    "    val_lambda[np.where((validation_sensible_att==1) & (y_val==0))[0]] == -1 ## Privileged denied\n",
    "    val_lambda[np.where((validation_sensible_att==1) & (y_val==1))[0]] == -1 ## Privileged granted\n",
    "    \n",
    "    test = CDataset(X_test[:,:2], y_test)\n",
    "    test_sensible_att = X_test[:,2]\n",
    "    \n",
    "    \n",
    "    ## GENERATING DATA FOR WHITE BOX ATTACK\n",
    "    X2,y2,X_control2 = generate_synthetic_data(False, np.array([i,i]))\n",
    "    formatted_X2=np.array([X2[:,0], X2[:,1], X_control2['s1']]).T ## Concatenating X with sensible att\n",
    "    \n",
    "    sec_ml_dataset_all2 = CDataset(X2, y2)\n",
    "    sensible_att_all2 = X_control2['s1']\n",
    "    \n",
    "    ## Splitting data. \n",
    "    X_train_val2, X_test2, y_train_val2, y_test2 = train_test_split(formatted_X2, y2, test_size=0.2, random_state=random_state)\n",
    "    X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train_val2, y_train_val2, test_size=0.5, random_state=random_state)\n",
    "    \n",
    "    training2 = CDataset(X_train2[:,:2], y_train2)\n",
    "    training_sensible_att2 = X_train2[:,2]\n",
    "    \n",
    "    validation2 = CDataset(X_val2[:,:2], y_val2)\n",
    "    validation_sensible_att2 = X_val2[:,2]\n",
    "    val_lambda2 = np.zeros(validation2.num_samples)\n",
    "    \n",
    "    ## Creating lambda vector\n",
    "    val_lambda2[np.where((validation_sensible_att2==0) & (y_val2==0))[0]] == 1 ## Unprivileged denied\n",
    "    val_lambda2[np.where((validation_sensible_att2==0) & (y_val2==1))[0]] == 1 ## Unprivileged granted\n",
    "    val_lambda2[np.where((validation_sensible_att2==1) & (y_val2==0))[0]] == -1 ## Privileged denied\n",
    "    val_lambda2[np.where((validation_sensible_att2==1) & (y_val2==1))[0]] == -1 ## Privileged granted\n",
    "    \n",
    "    test2 = CDataset(X_test2[:,:2], y_test)\n",
    "    test_sensible_att2 = X_test2[:,2]\n",
    "\n",
    "    scenario = {\n",
    "        \"name\": \"Use case 4 - {}\".format(n),\n",
    "        \"description\": \"Disparate impact attack. \\n Euclidean distance between group averages: {}\\n\".format(n),\n",
    "        \"training\": training,\n",
    "        \"training_sensible_att\" : training_sensible_att,\n",
    "        \"validation\" : validation,\n",
    "        \"validation_sensible_att\" : validation_sensible_att,\n",
    "        \"lambda_validation\" : val_lambda,\n",
    "        \"test\": test,\n",
    "        \"test_sensible_att\" : test_sensible_att,\n",
    "        \"all_data\" : sec_ml_dataset_all,\n",
    "        \"all_sensible_att\" : sensible_att_all,        \n",
    "        \"black_box_training\": training2,\n",
    "        \"black_box_training_sensible_att\" : training_sensible_att2,\n",
    "        \"black_box_validation\" : validation2,\n",
    "        \"black_box_validation_sensible_att\" : validation_sensible_att2,\n",
    "        \"black_box_lambda_validation\" : val_lambda2,\n",
    "        \"black_box_test\": test2,\n",
    "        \"black_box_test_sensible_att\" : test_sensible_att2,\n",
    "        \"black_box_all_data\" : sec_ml_dataset_all2,\n",
    "        \"black_box_all_sensible_att\" : sensible_att_all2,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    dimp_scenarios.append(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      " ==== Use case 4 - 0 ====\n",
      "    - Disparate impact attack. \n",
      " Euclidean distance between group averages: 0\n",
      "\n",
      "\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 10}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 44.38%\n",
      "Orig\n",
      "\tUnprivileged favorable1:  0.4266666666666667\n",
      "\tPrivileged favorable2:  0.49411764705882355\n",
      "DIMP:  -0.06745098039215686\n",
      "Creating 80 poisoning samples \n",
      "Attack started...\n",
      "Attack complete!\n",
      "->> white\n",
      "\tUnprivileged favorable1:  0.76\n",
      "\tPrivileged favorable2:  0.5647058823529412\n",
      "DIMP:  0.19529411764705884\n",
      "Estimating the best training parameters...\n",
      "The best training parameters are:  {'C': 1}\n",
      "Training of classifier complete!\n",
      "Accuracy on test set: 45.00%\n",
      "Creating 80 poisoning samples \n",
      "Attack started...\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for scenario in dimp_scenarios:\n",
    "    print(\"\\n\\n ==== {} ====\".format(scenario['name']))\n",
    "    print(\"    - {}\\n\".format(scenario['description']))\n",
    "    \n",
    "    ################################\n",
    "    ### ORIGINAL CLF PERFORMANCE ###\n",
    "    ################################\n",
    "    original_model, original_acc = train_LogReg(scenario[\"training\"], scenario[\"test\"])\n",
    "    \n",
    "    orig_y_pred = original_model.predict(scenario[\"test\"].X)\n",
    "    orig_FNR, orig_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    print(\"Orig\")\n",
    "    orig_disparate_imp = calculate_disparate_impact(orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    orig_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "    scenario['original_classifier'] = original_model\n",
    "    scenario['original_acc'] = original_acc\n",
    "    scenario['orig_d_imp'] = orig_disparate_imp\n",
    "    scenario['orig_odds'] = orig_odds_diff\n",
    "    scenario['orig_FNR'] = orig_FNR\n",
    "    scenario['orig_FPR'] = orig_FPR\n",
    "    \n",
    "\n",
    "    ########################\n",
    "    ### WHITE BOX ATTACK ###\n",
    "    ########################\n",
    "    white_pois_clf = deepcopy(original_model)\n",
    "    \n",
    "    privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "    privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "    \n",
    "    \n",
    "    white_pois_points, white_pois_tr = execute_adversarial_attack(white_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ## Retraining with poisoned points\n",
    "    white_pois_clf = white_pois_clf.fit(white_pois_tr)\n",
    "    white_pois_y_pred = white_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    metric = CMetricAccuracy()\n",
    "    white_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=white_pois_y_pred)\n",
    "    print(\"->> white\")\n",
    "    white_pois_disparate_imp = calculate_disparate_impact(white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    white_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    white_pois_FNR, white_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    \n",
    "\n",
    "    scenario['white_poisoned_classifier'] = white_pois_clf\n",
    "    scenario['white_poisoned_points'] = white_pois_points\n",
    "    scenario['white_pois_d_imp'] = white_pois_disparate_imp\n",
    "    scenario['white_odds'] = white_odds_diff\n",
    "    scenario['white_pois_y_pred'] = white_pois_y_pred\n",
    "    scenario['white_pois_acc'] = white_pois_acc\n",
    "    scenario['white_pois_FNR'] = white_pois_FNR\n",
    "    scenario['white_pois_FPR'] = white_pois_FPR\n",
    "    \n",
    "    \n",
    "    \n",
    "    ########################\n",
    "    ### BLACK BOX ATTACK ###\n",
    "    ########################\n",
    "    real_model, real_acc = train_SVM(scenario[\"training\"], scenario[\"test\"])\n",
    "    \n",
    "    surrogate_clf = deepcopy(original_model)\n",
    "    \n",
    "    black_pois_points, black_pois_tr = execute_adversarial_attack(surrogate_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ## Retraining with poisoned points\n",
    "    \n",
    "    black_pois_clf = deepcopy(real_model)\n",
    "    black_pois_clf = black_pois_clf.fit(black_pois_tr)\n",
    "    black_pois_y_pred = black_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    black_pois_acc = metric.performance_score(y_true=scenario[\"test\"].Y, y_pred=black_pois_y_pred)\n",
    "    print(\"->> black\")\n",
    "    black_pois_disparate_imp = calculate_disparate_impact(black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    black_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    black_pois_FNR, black_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    \n",
    "\n",
    "    scenario['black_poisoned_classifier'] = black_pois_clf\n",
    "    scenario['black_poisoned_points'] = black_pois_points\n",
    "    scenario['black_pois_d_imp'] = black_pois_disparate_imp\n",
    "    scenario['black_odds'] = black_odds_diff\n",
    "    scenario['black_pois_y_pred'] = black_pois_y_pred\n",
    "    scenario['black_pois_acc'] = black_pois_acc\n",
    "    scenario['black_pois_FNR'] = black_pois_FNR\n",
    "    scenario['black_pois_FPR'] = black_pois_FPR\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    ### CLASSIC POISONING ATTACK ###\n",
    "    ################################\n",
    "    normal_pois_clf = deepcopy(original_model)\n",
    "    \n",
    "    privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "    privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "    \n",
    "    \n",
    "    normal_pois_points, normal_pois_tr = execute_normal_poisoning_attack(normal_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "    ## Retraining with poisoned points\n",
    "    normal_pois_clf = normal_pois_clf.fit(normal_pois_tr)\n",
    "    normal_pois_y_pred = normal_pois_clf.predict(scenario[\"test\"].X)\n",
    "    \n",
    "    metric = CMetricAccuracy()\n",
    "    normal_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=normal_pois_y_pred)\n",
    "    print(\"->> normal\")\n",
    "    normal_pois_disparate_imp = calculate_disparate_impact(normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "    normal_pois_FNR, normal_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "    \n",
    "\n",
    "    scenario['normal_poisoned_classifier'] = normal_pois_clf\n",
    "    scenario['normal_poisoned_points'] = normal_pois_points\n",
    "    scenario['normal_pois_d_imp'] = normal_pois_disparate_imp\n",
    "    scenario['normal_odds'] = normal_odds_diff\n",
    "    scenario['normal_pois_y_pred'] = normal_pois_y_pred\n",
    "    scenario['normal_pois_acc'] = normal_pois_acc\n",
    "    scenario['normal_pois_FNR'] = normal_pois_FNR\n",
    "    scenario['normal_pois_FPR'] = normal_pois_FPR\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "def plot_disparate_impact(scenarios, data_dimp=None , n_scenarios=9, title=None):\n",
    "    \n",
    "    _x_ = [n for n in range(len(scenarios))]\n",
    "    \n",
    "    fig=plt.figure(figsize=[12,8])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(2,4) # 2 rows, 3 columns\n",
    "\n",
    "    ax1=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "    ax1.plot(_x_,[float(UC[\"original_acc\"]) for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax1.plot(_x_,[float(UC[\"white_pois_acc\"]) for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax1.plot(_x_,[float(UC[\"black_pois_acc\"]) for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax1.plot(_x_,[float(UC[\"normal_pois_acc\"]) for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    \n",
    "\n",
    "    ax2=fig.add_subplot(gs[0,2]) # First row, first column\n",
    "    ax2.set_title(\"Demographic parity\")\n",
    "    ax2.plot(_x_,[UC[\"orig_d_imp\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    if data_dimp is not None:\n",
    "        ax2.plot(_x_,data_dimp, c=\"darkgrey\", label=\"Original data\")\n",
    "    ax2.plot(_x_,[UC[\"white_pois_d_imp\"] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2.plot(_x_,[UC[\"black_pois_d_imp\"] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax2.plot(_x_,[UC[\"normal_pois_d_imp\"] for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    \n",
    "    ax2b=fig.add_subplot(gs[0,3]) # First row, first column\n",
    "    ax2b.set_title(\"Average odds difference\")\n",
    "    ax2b.plot(_x_,[UC[\"orig_odds\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax2b.plot(_x_,[UC[\"white_odds\"] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax2b.plot(_x_,[UC[\"black_odds\"] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax2b.plot(_x_,[UC[\"normal_odds\"] for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "\n",
    "    ax3=fig.add_subplot(gs[1,0]) # First row, second column\n",
    "    ax3.set_title(\"FNR privileged\")\n",
    "    ax3.plot(_x_,[UC[\"orig_FNR\"][\"FNR_privileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax3.plot(_x_,[UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax3.plot(_x_,[UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax3.plot(_x_,[UC[\"normal_pois_FNR\"]['FNR_privileged'] for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "\n",
    "    ax4=fig.add_subplot(gs[1,1]) # First row, third column\n",
    "    ax4.set_title(\"FNR unprivileged\")\n",
    "    ax4.plot(_x_,[UC[\"orig_FNR\"][\"FNR_unprivileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax4.plot(_x_,[UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax4.plot(_x_,[UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax4.plot(_x_,[UC[\"normal_pois_FNR\"]['FNR_unprivileged'] for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    ax4.plot([], [], c=\"gray\", label=\"Disparate impact in the data\")\n",
    "    \n",
    "    ax4.legend(bbox_to_anchor=(1.8, -0.1),fontsize=15)\n",
    "    \n",
    "    ax5=fig.add_subplot(gs[1,2]) # First row, second column\n",
    "    ax5.set_title(\"FPR privileged\")\n",
    "    ax5.plot(_x_,[UC[\"orig_FPR\"][\"FPR_privileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax5.plot(_x_,[UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax5.plot(_x_,[UC[\"black_pois_FPR\"]['FPR_privileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax5.plot(_x_,[UC[\"normal_pois_FPR\"]['FPR_privileged'] for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "\n",
    "    ax6=fig.add_subplot(gs[1,3]) # First row, third column\n",
    "    ax6.set_title(\"FPR unprivileged\")\n",
    "    ax6.plot(_x_,[UC[\"orig_FPR\"][\"FPR_unprivileged\"] for UC in scenarios], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax6.plot(_x_,[UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], c=\"red\", label=\"Poisoned classifier. White box attack.\")\n",
    "    ax6.plot(_x_,[UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], c=\"orange\", label=\"Poisoned classifier. Black box attack.\")\n",
    "    ax6.plot(_x_,[UC[\"normal_pois_FPR\"]['FPR_unprivileged'] for UC in scenarios], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    \n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_disparate_impact(dimp_scenarios, dimp_in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_decision_boundary_for_test(use_case):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action='once')\n",
    "    \n",
    "    clf = use_case['original_classifier']\n",
    "    pois_ds = use_case['white_poisoned_points']\n",
    "    \n",
    "    training_set = use_case['training']\n",
    "    validation_set = use_case['validation']\n",
    "    test_set = use_case['test']\n",
    "    \n",
    "    sensible_att_train = use_case['training_sensible_att']\n",
    "    sensible_att_val = use_case['validation_sensible_att']\n",
    "    sensible_att_test = use_case['test_sensible_att']\n",
    "\n",
    "    \n",
    "    ## Training data\n",
    "    tr_tmp_X = training_set.X.get_data()\n",
    "    tr_tmp_Y = training_set.Y.get_data().ravel()\n",
    "\n",
    "    tr1 = CDataset(tr_tmp_X[sensible_att_train == 0], tr_tmp_Y[sensible_att_train == 0])\n",
    "    tr2 = CDataset(tr_tmp_X[sensible_att_train == 1], tr_tmp_Y[sensible_att_train == 1])\n",
    "    \n",
    "    ## Validation data\n",
    "    val_tmp_X = validation_set.X.get_data()\n",
    "    val_tmp_Y = validation_set.Y.get_data().ravel()\n",
    "\n",
    "    val1 = CDataset(val_tmp_X[sensible_att_val == 0], val_tmp_Y[sensible_att_val == 0])\n",
    "    val2 = CDataset(val_tmp_X[sensible_att_val == 1], val_tmp_Y[sensible_att_val == 1])\n",
    "    \n",
    "    ## Test data\n",
    "    ts_tmp_X = test_set.X.get_data()\n",
    "    ts_tmp_Y = test_set.Y.get_data().ravel()\n",
    "\n",
    "    ts1 = CDataset(ts_tmp_X[sensible_att_test == 0], ts_tmp_Y[sensible_att_test == 0])\n",
    "    ts2 = CDataset(ts_tmp_X[sensible_att_test == 1], ts_tmp_Y[sensible_att_test == 1])\n",
    "    \n",
    "    \n",
    "    pois_clf = use_case['white_poisoned_classifier']\n",
    "\n",
    "    \n",
    "    pois_points_X = pois_ds.X.get_data()\n",
    "    pois_points_Y = pois_ds.Y.get_data().ravel()\n",
    "    \n",
    "    pois_ds1 = CDataset(pois_points_X[pois_points_Y==1], pois_points_Y[pois_points_Y==1])\n",
    "    pois_ds2 = CDataset(pois_points_X[pois_points_Y==0], pois_points_Y[pois_points_Y==0])\n",
    "    \n",
    "    pois_tr = deepcopy(training_set).append(pois_ds)\n",
    "    \n",
    "    # Define common bounds for the subplots\n",
    "    min_limit = min(pois_tr.X.min(), training_set.X.min())\n",
    "    max_limit = max(pois_tr.X.max(), training_set.X.max())\n",
    "    grid_limits = [[min_limit, max_limit], [min_limit, max_limit]]\n",
    "\n",
    "    from secml.figure import CFigure\n",
    "    fig = CFigure(15, 10)\n",
    "\n",
    "    fig.subplot(3, 2, 1)\n",
    "    fig.sp.title(\"Original classifier (training set)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "\n",
    "\n",
    "    fig.sp.plot_ds(tr1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(tr2, markersize=5, colors=['green', 'red'], markers='o')#, markerfacecolor=\"None\", markeredgecolor='g', markeredgewidth=1.5)\n",
    "    fig.sp.grid(grid_on=True)\n",
    "\n",
    "    fig.subplot(3, 2, 2)\n",
    "    fig.sp.title(\"Poisoned classifier (training set + poisoning points)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        pois_clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "    fig.sp.plot_ds(tr1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(tr2, markersize=5, colors=['green', 'red'], markers='o')\n",
    "    fig.sp.plot_ds(pois_ds1, markers='*', markersize=12, colors='darkred')\n",
    "    fig.sp.plot_ds(pois_ds2, markers='*', markersize=12, colors='darkgreen')\n",
    "    fig.sp.grid(grid_on=True)\n",
    "    \n",
    "\n",
    "    fig.subplot(3, 2, 3)\n",
    "    fig.sp.title(\"Original classifier (test set)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "\n",
    "    fig.sp.plot_ds(ts1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(ts2, markersize=5, colors=['red', 'green'], markers='o')\n",
    "    #fig.sp.text(0.05, -0.25, \"Accuracy on test set: {:.2%}\".format(acc),bbox=dict(facecolor='white'))\n",
    "    fig.sp.grid(grid_on=True)\n",
    "\n",
    "    fig.subplot(3, 2, 4)\n",
    "    fig.sp.title(\"Poisoned classifier (test set)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        pois_clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "\n",
    "    fig.sp.plot_ds(ts1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(ts2, markersize=5, colors=['red', 'green'], markers='o')\n",
    "    #fig.sp.text(0.05, -0.25, \"Accuracy on test set: {:.2%}\".format(pois_acc),bbox=dict(facecolor='white'))\n",
    "    \n",
    "    fig.subplot(3, 2, 5)\n",
    "    fig.sp.title(\"Original classifier (validation set)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "    fig.sp.plot_ds(val1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(val2, markersize=5, colors=['green', 'red'], markers='o')\n",
    "    fig.sp.grid(grid_on=True)\n",
    "    \n",
    "    fig.subplot(3, 2, 6)\n",
    "    fig.sp.title(\"Poisoned classifier (validation set + poisoning points)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        pois_clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "    fig.sp.plot_ds(val1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(val2, markersize=5, colors=['green', 'red'], markers='o')\n",
    "    fig.sp.plot_ds(pois_ds1, markers='*', markersize=12, colors='darkred')\n",
    "    fig.sp.plot_ds(pois_ds2, markers='*', markersize=12, colors='darkgreen')\n",
    "    fig.sp.grid(grid_on=True)\n",
    "\n",
    "    fig.sp.grid(grid_on=True)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_decision_boundary_for_test(dimp_scenarios[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_decision_boundary_for_test2(use_case):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action='once')\n",
    "    \n",
    "    clf = use_case['original_classifier']\n",
    "    pois_ds = use_case['white_poisoned_points']\n",
    "    \n",
    "    training_set = use_case['training']\n",
    "    validation_set = use_case['validation']\n",
    "    test_set = use_case['test']\n",
    "    \n",
    "    sensible_att_train = use_case['training_sensible_att']\n",
    "    sensible_att_val = use_case['validation_sensible_att']\n",
    "    sensible_att_test = use_case['test_sensible_att']\n",
    "\n",
    "    \n",
    "    ## Training data\n",
    "    tr_tmp_X = training_set.X.get_data()\n",
    "    tr_tmp_Y = training_set.Y.get_data().ravel()\n",
    "\n",
    "    tr1 = CDataset(tr_tmp_X[sensible_att_train == 0], tr_tmp_Y[sensible_att_train == 0])\n",
    "    tr2 = CDataset(tr_tmp_X[sensible_att_train == 1], tr_tmp_Y[sensible_att_train == 1])\n",
    "    \n",
    "    ## Validation data\n",
    "    val_tmp_X = validation_set.X.get_data()\n",
    "    val_tmp_Y = validation_set.Y.get_data().ravel()\n",
    "\n",
    "    val1 = CDataset(val_tmp_X[sensible_att_val == 0], val_tmp_Y[sensible_att_val == 0])\n",
    "    val2 = CDataset(val_tmp_X[sensible_att_val == 1], val_tmp_Y[sensible_att_val == 1])\n",
    "    \n",
    "    ## Test data\n",
    "    ts_tmp_X = test_set.X.get_data()\n",
    "    ts_tmp_Y = test_set.Y.get_data().ravel()\n",
    "\n",
    "    ts1 = CDataset(ts_tmp_X[sensible_att_test == 0], ts_tmp_Y[sensible_att_test == 0])\n",
    "    ts2 = CDataset(ts_tmp_X[sensible_att_test == 1], ts_tmp_Y[sensible_att_test == 1])\n",
    "    \n",
    "    \n",
    "    pois_clf = use_case['white_poisoned_classifier']\n",
    "\n",
    "    \n",
    "    pois_points_X = pois_ds.X.get_data()\n",
    "    pois_points_Y = pois_ds.Y.get_data().ravel()\n",
    "    \n",
    "    pois_ds1 = CDataset(pois_points_X[pois_points_Y==1], pois_points_Y[pois_points_Y==1])\n",
    "    pois_ds2 = CDataset(pois_points_X[pois_points_Y==0], pois_points_Y[pois_points_Y==0])\n",
    "    \n",
    "    pois_tr = deepcopy(training_set).append(pois_ds)\n",
    "    \n",
    "    # Define common bounds for the subplots\n",
    "    min_limit = min(pois_tr.X.min(), training_set.X.min())\n",
    "    max_limit = max(pois_tr.X.max(), training_set.X.max())\n",
    "    grid_limits = [[min_limit, max_limit], [min_limit, max_limit]]\n",
    "\n",
    "    from secml.figure import CFigure\n",
    "    fig = CFigure(6, 12)\n",
    "\n",
    "    fig.subplot(1, 2, 1)\n",
    "    #fig.sp.title(\"Original classifier (training set)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "\n",
    "\n",
    "    fig.sp.plot_ds(tr1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(tr2, markersize=5, colors=['green', 'red'], markers='o')#, markerfacecolor=\"None\", markeredgecolor='g', markeredgewidth=1.5)\n",
    "    fig.sp.grid(grid_on=True)\n",
    "\n",
    "    fig.subplot(1, 2, 2)\n",
    "    #fig.sp.title(\"Poisoned classifier (training set + poisoning points)\")\n",
    "    fig.sp.plot_decision_regions(\n",
    "        pois_clf, n_grid_points=200, grid_limits=grid_limits, cmap=\"RdYlGn\")\n",
    "    fig.sp.plot_ds(tr1, markersize=7, colors=['red', 'green'], markers='X')\n",
    "    fig.sp.plot_ds(tr2, markersize=5, colors=['green', 'red'], markers='o')\n",
    "    fig.sp.plot_ds(pois_ds1, markers='*', markersize=12, colors='darkred')\n",
    "    fig.sp.plot_ds(pois_ds2, markers='*', markersize=12, colors='darkgreen')\n",
    "    fig.sp.grid(grid_on=True)\n",
    "    plt.legend()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_2d_decision_boundary_for_test2(dimp_scenarios[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "_datasets = []\n",
    "_sensible_atts = []\n",
    "_formatted_Xs = []\n",
    "\n",
    "_dimp_in_data = []\n",
    "_euc_distances = []\n",
    "\n",
    "\n",
    "\n",
    "for n in RANGE:\n",
    "    ## Generating data\n",
    "    euc_dist = n\n",
    "    i = np.sqrt((euc_dist**2)/2)\n",
    "    X,y,X_control = generate_synthetic_data(False, np.array([i,i]))\n",
    "    formatted_X=np.array([X[:,0], X[:,1], X_control['s1']]).T ## Concatenating X with sensible att\n",
    "\n",
    "    sec_ml_dataset_all = CDataset(X, y)\n",
    "    \n",
    "    \n",
    "    sensible_att_all = X_control['s1']\n",
    "    \n",
    "    _datasets.append(sec_ml_dataset_all)\n",
    "    _sensible_atts.append(sensible_att_all)\n",
    "    _formatted_Xs.append(formatted_X)\n",
    "    \n",
    "    _euc_distances.append(n)\n",
    "    _dimp_in_data.append(calculate_disparate_impact(sec_ml_dataset_all.Y.get_data(), sensible_att_all)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## Multiple runs\n",
    "def compare_multiple_runs(num_reps = 5):\n",
    "    reps_results = []\n",
    "    for i in range(num_reps):\n",
    "        _count = 0\n",
    "        \n",
    "        \n",
    "       \n",
    "        _scenarios = []\n",
    "\n",
    "        for n in RANGE:\n",
    "            \n",
    "            sec_ml_dataset_all = _datasets[_count]\n",
    "            sensible_att_all = _sensible_atts[_count]\n",
    "            formatted_X = _formatted_Xs[_count]\n",
    "            \n",
    "            X = sec_ml_dataset_all.X.get_data()\n",
    "            y = sec_ml_dataset_all.Y.get_data()\n",
    "            \n",
    "            \n",
    "            _count+=1\n",
    "            \n",
    "            \n",
    "            ## Splitting data. \n",
    "            X_train_val, X_test, y_train_val, y_test = train_test_split(formatted_X, y, test_size=0.2, random_state=random_state)\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            training = CDataset(X_train[:,:2], y_train)\n",
    "            training_sensible_att = X_train[:,2]\n",
    "\n",
    "            validation = CDataset(X_val[:,:2], y_val)\n",
    "            validation_sensible_att = X_val[:,2]\n",
    "            val_lambda = np.zeros(validation.num_samples)\n",
    "\n",
    "            ## Creating lambda vector\n",
    "            val_lambda[np.where((validation_sensible_att==0) & (y_val==0))[0]] == 1 ## Unprivileged denied\n",
    "            val_lambda[np.where((validation_sensible_att==0) & (y_val==1))[0]] == 1 ## Unprivileged granted\n",
    "            val_lambda[np.where((validation_sensible_att==1) & (y_val==0))[0]] == -1 ## Privileged denied\n",
    "            val_lambda[np.where((validation_sensible_att==1) & (y_val==1))[0]] == -1 ## Privileged granted\n",
    "\n",
    "            test = CDataset(X_test[:,:2], y_test)\n",
    "            test_sensible_att = X_test[:,2]\n",
    "\n",
    "\n",
    "            ## GENERATING DATA FOR WHITE BOX ATTACK\n",
    "            X2,y2,X_control2 = generate_synthetic_data(False, np.array([i,i]))\n",
    "            formatted_X2=np.array([X2[:,0], X2[:,1], X_control2['s1']]).T ## Concatenating X with sensible att\n",
    "\n",
    "            sec_ml_dataset_all2 = CDataset(X2, y2)\n",
    "            sensible_att_all2 = X_control2['s1']\n",
    "\n",
    "            ## Splitting data. \n",
    "            X_train_val2, X_test2, y_train_val2, y_test2 = train_test_split(formatted_X2, y2, test_size=0.2, random_state=random_state)\n",
    "            X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train_val2, y_train_val2, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            training2 = CDataset(X_train2[:,:2], y_train2)\n",
    "            training_sensible_att2 = X_train2[:,2]\n",
    "\n",
    "            validation2 = CDataset(X_val2[:,:2], y_val2)\n",
    "            validation_sensible_att2 = X_val2[:,2]\n",
    "            val_lambda2 = np.zeros(validation2.num_samples)\n",
    "\n",
    "            ## Creating lambda vector\n",
    "            val_lambda2[np.where((validation_sensible_att2==0) & (y_val2==0))[0]] == 1 ## Unprivileged denied\n",
    "            val_lambda2[np.where((validation_sensible_att2==0) & (y_val2==1))[0]] == 1 ## Unprivileged granted\n",
    "            val_lambda2[np.where((validation_sensible_att2==1) & (y_val2==0))[0]] == -1 ## Privileged denied\n",
    "            val_lambda2[np.where((validation_sensible_att2==1) & (y_val2==1))[0]] == -1 ## Privileged granted\n",
    "\n",
    "            test2 = CDataset(X_test2[:,:2], y_test)\n",
    "            test_sensible_att2 = X_test2[:,2]\n",
    "\n",
    "            scenario = {\n",
    "                \"name\": \"Use case 4 - {}\".format(n),\n",
    "                \"description\": \"Disparate impact attack. \\n Euclidean distance between group averages: {}\\n\".format(n),\n",
    "                \"training\": training,\n",
    "                \"training_sensible_att\" : training_sensible_att,\n",
    "                \"validation\" : validation,\n",
    "                \"validation_sensible_att\" : validation_sensible_att,\n",
    "                \"lambda_validation\" : val_lambda,\n",
    "                \"test\": test,\n",
    "                \"test_sensible_att\" : test_sensible_att,\n",
    "                \"all_data\" : sec_ml_dataset_all,\n",
    "                \"all_sensible_att\" : sensible_att_all,        \n",
    "                \"black_box_training\": training2,\n",
    "                \"black_box_training_sensible_att\" : training_sensible_att2,\n",
    "                \"black_box_validation\" : validation2,\n",
    "                \"black_box_validation_sensible_att\" : validation_sensible_att2,\n",
    "                \"black_box_lambda_validation\" : val_lambda2,\n",
    "                \"black_box_test\": test2,\n",
    "                \"black_box_test_sensible_att\" : test_sensible_att2,\n",
    "                \"black_box_all_data\" : sec_ml_dataset_all2,\n",
    "                \"black_box_all_sensible_att\" : sensible_att_all2,\n",
    "            }\n",
    "\n",
    "\n",
    "            _scenarios.append(scenario)\n",
    "    \n",
    "        for scenario in _scenarios:\n",
    "            print(\"\\n\\n ==== {} ====\".format(scenario['name']))\n",
    "            print(\"    - {}\\n\".format(scenario['description']))\n",
    "\n",
    "            ################################\n",
    "            ### ORIGINAL CLF PERFORMANCE ###\n",
    "            ################################\n",
    "            original_model, original_acc = train_LogReg(scenario[\"training\"], scenario[\"test\"])\n",
    "\n",
    "            orig_y_pred = original_model.predict(scenario[\"test\"].X)\n",
    "            orig_FNR, orig_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "            print(\"Orig\")\n",
    "            orig_disparate_imp = calculate_disparate_impact(orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            orig_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), orig_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "\n",
    "            scenario['original_classifier'] = original_model\n",
    "            scenario['original_acc'] = original_acc\n",
    "            scenario['orig_d_imp'] = orig_disparate_imp\n",
    "            scenario['orig_odds'] = orig_odds_diff\n",
    "            scenario['orig_FNR'] = orig_FNR\n",
    "            scenario['orig_FPR'] = orig_FPR\n",
    "\n",
    "\n",
    "            ########################\n",
    "            ### WHITE BOX ATTACK ###\n",
    "            ########################\n",
    "            white_pois_clf = deepcopy(original_model)\n",
    "\n",
    "            privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "            privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "\n",
    "\n",
    "            white_pois_points, white_pois_tr = execute_adversarial_attack(white_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "            ## Retraining with poisoned points\n",
    "            white_pois_clf = white_pois_clf.fit(white_pois_tr)\n",
    "            white_pois_y_pred = white_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "            metric = CMetricAccuracy()\n",
    "            white_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=white_pois_y_pred)\n",
    "            print(\"->> white\")\n",
    "            white_pois_disparate_imp = calculate_disparate_impact(white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            white_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            white_pois_FNR, white_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), white_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "\n",
    "\n",
    "            scenario['white_poisoned_classifier'] = white_pois_clf\n",
    "            scenario['white_poisoned_points'] = white_pois_points\n",
    "            scenario['white_pois_d_imp'] = white_pois_disparate_imp\n",
    "            scenario['white_odds'] = white_odds_diff\n",
    "            scenario['white_pois_y_pred'] = white_pois_y_pred\n",
    "            scenario['white_pois_acc'] = white_pois_acc\n",
    "            scenario['white_pois_FNR'] = white_pois_FNR\n",
    "            scenario['white_pois_FPR'] = white_pois_FPR\n",
    "\n",
    "\n",
    "\n",
    "            ########################\n",
    "            ### BLACK BOX ATTACK ###\n",
    "            ########################\n",
    "            real_model, real_acc = train_SVM(scenario[\"training\"], scenario[\"test\"])\n",
    "\n",
    "            surrogate_clf = deepcopy(original_model)\n",
    "\n",
    "            black_pois_points, black_pois_tr = execute_adversarial_attack(surrogate_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "            ## Retraining with poisoned points\n",
    "\n",
    "            black_pois_clf = deepcopy(real_model)\n",
    "            black_pois_clf = black_pois_clf.fit(black_pois_tr)\n",
    "            black_pois_y_pred = black_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "            black_pois_acc = metric.performance_score(y_true=scenario[\"test\"].Y, y_pred=black_pois_y_pred)\n",
    "            print(\"->> black\")\n",
    "            black_pois_disparate_imp = calculate_disparate_impact(black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            black_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            black_pois_FNR, black_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), black_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "\n",
    "\n",
    "            scenario['black_poisoned_classifier'] = black_pois_clf\n",
    "            scenario['black_poisoned_points'] = black_pois_points\n",
    "            scenario['black_pois_d_imp'] = black_pois_disparate_imp\n",
    "            scenario['black_odds'] = black_odds_diff\n",
    "            scenario['black_pois_y_pred'] = black_pois_y_pred\n",
    "            scenario['black_pois_acc'] = black_pois_acc\n",
    "            scenario['black_pois_FNR'] = black_pois_FNR\n",
    "            scenario['black_pois_FPR'] = black_pois_FPR\n",
    "\n",
    "\n",
    "\n",
    "            ################################\n",
    "            ### CLASSIC POISONING ATTACK ###\n",
    "            ################################\n",
    "            normal_pois_clf = deepcopy(original_model)\n",
    "\n",
    "            privileged_condition_valid = np.ones(scenario['validation'].num_samples)\n",
    "            privileged_condition_valid[scenario[\"validation_sensible_att\"] == 0] == -1\n",
    "\n",
    "\n",
    "            normal_pois_points, normal_pois_tr = execute_normal_poisoning_attack(normal_pois_clf, scenario[\"training\"], scenario[\"validation\"], scenario[\"test\"], scenario[\"test_sensible_att\"], scenario[\"validation_sensible_att\"])\n",
    "            ## Retraining with poisoned points\n",
    "            normal_pois_clf = normal_pois_clf.fit(normal_pois_tr)\n",
    "            normal_pois_y_pred = normal_pois_clf.predict(scenario[\"test\"].X)\n",
    "\n",
    "            metric = CMetricAccuracy()\n",
    "            normal_pois_acc = metric.performance_score(scenario[\"test\"].Y, y_pred=normal_pois_y_pred)\n",
    "            print(\"->> normal\")\n",
    "            normal_pois_disparate_imp = calculate_disparate_impact(normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            normal_odds_diff = get_average_odds_difference(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"])\n",
    "            normal_pois_FNR, normal_pois_FPR = get_error_rates(scenario[\"test\"].Y.get_data(), normal_pois_y_pred.get_data(), scenario[\"test_sensible_att\"], 1, 1)\n",
    "\n",
    "\n",
    "            scenario['normal_poisoned_classifier'] = normal_pois_clf\n",
    "            scenario['normal_poisoned_points'] = normal_pois_points\n",
    "            scenario['normal_pois_d_imp'] = normal_pois_disparate_imp\n",
    "            scenario['normal_odds'] = normal_odds_diff\n",
    "            scenario['normal_pois_y_pred'] = normal_pois_y_pred\n",
    "            scenario['normal_pois_acc'] = normal_pois_acc\n",
    "            scenario['normal_pois_FNR'] = normal_pois_FNR\n",
    "            scenario['normal_pois_FPR'] = normal_pois_FPR  \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            reps_results.append(_scenarios)\n",
    "\n",
    "        \n",
    "    return reps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "_results = compare_multiple_runs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_use_case_multiple_runs(_cases, data_dimp,title=None):\n",
    "    \n",
    "    _x_ = [n for n in range(len(_cases[0]))]\n",
    "    \n",
    "    fig=plt.figure(figsize=[16,8])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(2,4) # 2 rows, 3 columns\n",
    "\n",
    "    ax1=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    orig_accs = []\n",
    "    white_accs = []\n",
    "    black_accs = []\n",
    "    pois_accs = []\n",
    "    \n",
    "    orig_dimp = []\n",
    "    white_dimp = []\n",
    "    black_dimp = []\n",
    "    pois_dimp = []\n",
    "    \n",
    "    orig_odds = []\n",
    "    white_odds = []\n",
    "    black_odds = []\n",
    "    pois_odds = []\n",
    "    \n",
    "    orig_fpr_priv = []\n",
    "    white_fpr_priv = []\n",
    "    black_fpr_priv = []\n",
    "    pois_fpr_priv = []\n",
    "    \n",
    "    orig_fpr_unpriv = []\n",
    "    white_fpr_unpriv = []\n",
    "    black_fpr_unpriv = []\n",
    "    pois_fpr_unpriv = []\n",
    "    \n",
    "    orig_fnr_priv = []\n",
    "    white_fnr_priv = []\n",
    "    black_fnr_priv = []\n",
    "    pois_fnr_priv = []\n",
    "    \n",
    "    orig_fnr_unpriv = []\n",
    "    white_fnr_unpriv = []\n",
    "    black_fnr_unpriv = []\n",
    "    pois_fnr_unpriv = []\n",
    "    \n",
    "    orig_odds_diff = []\n",
    "    white_odds_diff = []\n",
    "    black_odds_diff = []\n",
    "    pois_odds_diff = []\n",
    "    \n",
    "            \n",
    "    dimp_data = []\n",
    "    \n",
    "    for i in range(len(_cases)):\n",
    "        \n",
    "        pois_cases = _cases[i]\n",
    "        \n",
    "        orig_accs.append([float(UC[\"original_acc\"]) for UC in pois_cases])\n",
    "        white_accs.append([float(UC[\"white_pois_acc\"]) for UC in pois_cases])\n",
    "        black_accs.append([float(UC[\"black_pois_acc\"]) for UC in pois_cases])\n",
    "        pois_accs.append([float(UC[\"normal_pois_acc\"]) for UC in pois_cases])\n",
    "\n",
    "        orig_dimp.append([UC[\"orig_d_imp\"] for UC in pois_cases])\n",
    "        white_dimp.append([UC[\"white_pois_d_imp\"] for UC in pois_cases])\n",
    "        black_dimp.append([UC[\"black_pois_d_imp\"] for UC in pois_cases])\n",
    "        pois_dimp.append([UC[\"normal_pois_d_imp\"] for UC in pois_cases])\n",
    "        \n",
    "        orig_odds.append([UC[\"orig_odds\"] for UC in pois_cases])\n",
    "        white_odds.append([UC[\"white_odds\"] for UC in pois_cases])\n",
    "        black_odds.append([UC[\"black_odds\"] for UC in pois_cases])\n",
    "        pois_odds.append([UC[\"normal_odds\"] for UC in pois_cases])\n",
    "        \n",
    "        orig_fpr_priv.append([UC[\"orig_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        white_fpr_priv.append([UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        black_fpr_priv.append([UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        pois_fpr_priv.append([UC[\"normal_pois_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        \n",
    "        orig_fpr_unpriv.append([UC[\"orig_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        white_fpr_unpriv.append([UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        black_fpr_unpriv.append([UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        pois_fpr_unpriv.append([UC[\"normal_pois_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        \n",
    "        orig_fnr_priv.append([UC[\"orig_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        white_fnr_priv.append([UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        black_fnr_priv.append([UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        pois_fnr_priv.append([UC[\"normal_pois_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        \n",
    "        orig_fnr_unpriv.append([UC[\"orig_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        white_fnr_unpriv.append([UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        black_fnr_unpriv.append([UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        pois_fnr_unpriv.append([UC[\"normal_pois_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        \n",
    "    ALPHA=0.2\n",
    "\n",
    "    epochs = list(range(len(orig_accs[0])))\n",
    "\n",
    "    mean1 = np.array(orig_accs).mean(0)\n",
    "    std1 = np.array(orig_accs).std(0)\n",
    "    mean2 = np.array(white_accs).mean(0)\n",
    "    std2 = np.array(white_accs).std(0)\n",
    "    mean3 = np.array(black_accs).mean(0)\n",
    "    std3 = np.array(black_accs).std(0)\n",
    "    mean4 = np.array(pois_accs).mean(0)\n",
    "    std4 = np.array(pois_accs).std(0)\n",
    "    \n",
    "    mean0 = np.array(dimp_data).mean(0) \n",
    "    std0 = np.array(dimp_data).std(0)\n",
    "\n",
    "    \n",
    "    ax1=fig.add_subplot(gs[0,:2]) # First row, second column\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "    ax1.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax1.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax1.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax1.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax1.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax1.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax1.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax1.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "\n",
    "    \n",
    "    mean1 = np.array(orig_dimp).mean(0)\n",
    "    std1 = np.array(orig_dimp).std(0)\n",
    "    mean2 = np.array(white_dimp).mean(0)\n",
    "    std2 = np.array(white_dimp).std(0)\n",
    "    mean3 = np.array(black_dimp).mean(0)\n",
    "    std3 = np.array(black_dimp).std(0)\n",
    "    mean4 = np.array(pois_dimp).mean(0)\n",
    "    std4 = np.array(pois_dimp).std(0)\n",
    "\n",
    "    \n",
    "    ax2=fig.add_subplot(gs[0,2]) # First row, second column\n",
    "    ax2.set_title(\"Demographic parity\")\n",
    "    \n",
    "    ax2.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax2.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax2.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax2.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax2.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax2.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax2.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax2.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    #ax2.plot(_x_, mean0, c=\"gray\", label=\"Original data\")\n",
    "    ##ax2.fill_between(_x_, mean0-std0, mean0+std0 ,alpha=ALPHA, color=\"gray\")\n",
    "    \n",
    "    \n",
    "    mean1 = np.array(orig_odds).mean(0)\n",
    "    std1 = np.array(orig_odds).std(0)\n",
    "    mean2 = np.array(white_odds).mean(0)\n",
    "    std2 = np.array(white_odds).std(0)\n",
    "    mean3 = np.array(black_odds).mean(0)\n",
    "    std3 = np.array(black_odds).std(0)\n",
    "    mean4 = np.array(pois_odds).mean(0)\n",
    "    std4 = np.array(pois_odds).std(0)\n",
    "    \n",
    "    ax2b=fig.add_subplot(gs[0,3]) # First row, second column\n",
    "    ax2b.set_title(\"Average odds difference\")\n",
    "\n",
    "    ax2b.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax2b.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax2b.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax2b.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax2b.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax2b.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax2b.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax2b.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    mean1 = np.array(orig_fnr_priv).mean(0)\n",
    "    std1 = np.array(orig_fnr_priv).std(0)\n",
    "    mean2 = np.array(white_fnr_priv).mean(0)\n",
    "    std2 = np.array(white_fnr_priv).std(0)\n",
    "    mean3 = np.array(black_fnr_priv).mean(0)\n",
    "    std3 = np.array(black_fnr_priv).std(0)\n",
    "    mean4 = np.array(pois_fnr_priv).mean(0)\n",
    "    std4 = np.array(pois_fnr_priv).std(0)\n",
    "\n",
    "    ax3=fig.add_subplot(gs[1,0]) # First row, second column\n",
    "    ax3.set_title(\"FNR privileged\")\n",
    "    \n",
    "    ax3.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax3.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax3.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax3.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax3.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax3.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax3.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax3.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    \n",
    "    \n",
    "    mean1 = np.array(orig_fnr_unpriv).mean(0)\n",
    "    std1 = np.array(orig_fnr_unpriv).std(0)\n",
    "    mean2 = np.array(white_fnr_unpriv).mean(0)\n",
    "    std2 = np.array(white_fnr_unpriv).std(0)\n",
    "    mean3 = np.array(black_fnr_unpriv).mean(0)\n",
    "    std3 = np.array(black_fnr_unpriv).std(0)\n",
    "    mean4 = np.array(pois_fnr_unpriv).mean(0)\n",
    "    std4 = np.array(pois_fnr_unpriv).std(0)\n",
    "    \n",
    "    ax4=fig.add_subplot(gs[1,1]) # First row, third column\n",
    "    ax4.set_title(\"FNR unprivileged\")\n",
    "    \n",
    "    ax4.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax4.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax4.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax4.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax4.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax4.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax4.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax4.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    ax4.legend(bbox_to_anchor=(1.8, -0.1),fontsize=15)\n",
    "    \n",
    "    mean1 = np.array(orig_fpr_priv).mean(0)\n",
    "    std1 = np.array(orig_fpr_priv).std(0)\n",
    "    mean2 = np.array(white_fpr_priv).mean(0)\n",
    "    std2 = np.array(white_fpr_priv).std(0)\n",
    "    mean3 = np.array(black_fpr_priv).mean(0)\n",
    "    std3 = np.array(black_fpr_priv).std(0)\n",
    "    mean4 = np.array(pois_fpr_priv).mean(0)\n",
    "    std4 = np.array(pois_fpr_priv).std(0)\n",
    "    \n",
    "    ax5=fig.add_subplot(gs[1,2]) # First row, second column\n",
    "    ax5.set_title(\"FPR privileged\")\n",
    "    \n",
    "    ax5.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax5.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax5.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax5.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax5.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax5.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax5.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax5.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    \n",
    "    \n",
    "    mean1 = np.array(orig_fpr_unpriv).mean(0)\n",
    "    std1 = np.array(orig_fpr_unpriv).std(0)\n",
    "    mean2 = np.array(white_fpr_unpriv).mean(0)\n",
    "    std2 = np.array(white_fpr_unpriv).std(0)\n",
    "    mean3 = np.array(black_fpr_unpriv).mean(0)\n",
    "    std3 = np.array(black_fpr_unpriv).std(0)\n",
    "    mean4 = np.array(pois_fpr_unpriv).mean(0)\n",
    "    std4 = np.array(pois_fpr_unpriv).std(0)\n",
    "    \n",
    "    ax6=fig.add_subplot(gs[1,3]) # First row, third column\n",
    "    ax6.set_title(\"FPR unprivileged\")\n",
    "    \n",
    "    ax6.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax6.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax6.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax6.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax6.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax6.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    ax6.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax6.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_use_case_multiple_runs(_results, np.ones(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "def smooth_line(x,y, n_points =3):\n",
    "\n",
    "\n",
    "    # 300 represents number of points to make between T.min and T.max\n",
    "    xnew = np.linspace(x.min(), x.max(), n_points) \n",
    "\n",
    "    spl = make_interp_spline(x, y, k=3)  # type: BSpline\n",
    "    power_smooth = spl(xnew)\n",
    "\n",
    "    plt.plot(xnew, power_smooth)\n",
    "    return xnew, power_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_use_case_multiple_runs_v2(_cases, data_dimp,title=None, _x_=None):\n",
    "    if _x_ is None:\n",
    "        _x_ = [n for n in range(len(_cases[0]))]\n",
    "    \n",
    "    fig=plt.figure(figsize=[16,4])\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=14)\n",
    "\n",
    "    gs=GridSpec(1,3) # 2 rows, 3 columns\n",
    "\n",
    "    orig_accs = []\n",
    "    white_accs = []\n",
    "    black_accs = []\n",
    "    pois_accs = []\n",
    "    \n",
    "    orig_dimp = []\n",
    "    white_dimp = []\n",
    "    black_dimp = []\n",
    "    pois_dimp = []\n",
    "    \n",
    "    orig_odds = []\n",
    "    white_odds = []\n",
    "    black_odds = []\n",
    "    pois_odds = []\n",
    "    \n",
    "    orig_fpr_priv = []\n",
    "    white_fpr_priv = []\n",
    "    black_fpr_priv = []\n",
    "    pois_fpr_priv = []\n",
    "    \n",
    "    orig_fpr_unpriv = []\n",
    "    white_fpr_unpriv = []\n",
    "    black_fpr_unpriv = []\n",
    "    pois_fpr_unpriv = []\n",
    "    \n",
    "    orig_fnr_priv = []\n",
    "    white_fnr_priv = []\n",
    "    black_fnr_priv = []\n",
    "    pois_fnr_priv = []\n",
    "    \n",
    "    orig_fnr_unpriv = []\n",
    "    white_fnr_unpriv = []\n",
    "    black_fnr_unpriv = []\n",
    "    pois_fnr_unpriv = []\n",
    "    \n",
    "    orig_odds_diff = []\n",
    "    white_odds_diff = []\n",
    "    black_odds_diff = []\n",
    "    pois_odds_diff = []\n",
    "    \n",
    "            \n",
    "    dimp_data = []\n",
    "    \n",
    "    for i in range(len(_cases)):\n",
    "        \n",
    "        pois_cases = _cases[i]\n",
    "        \n",
    "        orig_accs.append([float(UC[\"original_acc\"]) for UC in pois_cases])\n",
    "        white_accs.append([float(UC[\"white_pois_acc\"]) for UC in pois_cases])\n",
    "        black_accs.append([float(UC[\"black_pois_acc\"]) for UC in pois_cases])\n",
    "        pois_accs.append([float(UC[\"normal_pois_acc\"]) for UC in pois_cases])\n",
    "\n",
    "        orig_dimp.append([UC[\"orig_d_imp\"] for UC in pois_cases])\n",
    "        white_dimp.append([UC[\"white_pois_d_imp\"] for UC in pois_cases])\n",
    "        black_dimp.append([UC[\"black_pois_d_imp\"] for UC in pois_cases])\n",
    "        pois_dimp.append([UC[\"normal_pois_d_imp\"] for UC in pois_cases])\n",
    "        \n",
    "        orig_odds.append([UC[\"orig_odds\"] for UC in pois_cases])\n",
    "        white_odds.append([UC[\"white_odds\"] for UC in pois_cases])\n",
    "        black_odds.append([UC[\"black_odds\"] for UC in pois_cases])\n",
    "        pois_odds.append([UC[\"normal_odds\"] for UC in pois_cases])\n",
    "        \n",
    "        orig_fpr_priv.append([UC[\"orig_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        white_fpr_priv.append([UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        black_fpr_priv.append([UC[\"white_pois_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        pois_fpr_priv.append([UC[\"normal_pois_FPR\"]['FPR_privileged'] for UC in pois_cases])\n",
    "        \n",
    "        orig_fpr_unpriv.append([UC[\"orig_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        white_fpr_unpriv.append([UC[\"white_pois_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        black_fpr_unpriv.append([UC[\"black_pois_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        pois_fpr_unpriv.append([UC[\"normal_pois_FPR\"]['FPR_unprivileged'] for UC in pois_cases])\n",
    "        \n",
    "        orig_fnr_priv.append([UC[\"orig_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        white_fnr_priv.append([UC[\"white_pois_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        black_fnr_priv.append([UC[\"black_pois_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        pois_fnr_priv.append([UC[\"normal_pois_FNR\"]['FNR_privileged'] for UC in pois_cases])\n",
    "        \n",
    "        orig_fnr_unpriv.append([UC[\"orig_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        white_fnr_unpriv.append([UC[\"white_pois_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        black_fnr_unpriv.append([UC[\"black_pois_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        pois_fnr_unpriv.append([UC[\"normal_pois_FNR\"]['FNR_unprivileged'] for UC in pois_cases])\n",
    "        \n",
    "    ALPHA=0.2\n",
    "\n",
    "    epochs = list(range(len(orig_accs[0])))\n",
    "\n",
    "    mean1 = np.array(orig_accs).mean(0)\n",
    "    std1 = np.array(orig_accs).std(0)\n",
    "    mean2 = np.array(white_accs).mean(0)\n",
    "    std2 = np.array(white_accs).std(0)\n",
    "    mean3 = np.array(black_accs).mean(0)\n",
    "    std3 = np.array(black_accs).std(0)\n",
    "    mean4 = np.array(pois_accs).mean(0)\n",
    "    std4 = np.array(pois_accs).std(0)\n",
    "    \n",
    "    mean0 = np.array(dimp_data).mean(0) \n",
    "    std0 = np.array(dimp_data).std(0)\n",
    "\n",
    "    \n",
    "    ax1=fig.add_subplot(gs[0,0]) # First row, second column\n",
    "    ax1.set_title(\"Accuracy\")\n",
    "    \n",
    "\n",
    "    \n",
    "    ax1.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax1.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax1.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax1.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax1.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax1.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax1.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax1.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    \"\"\"\n",
    "    ax1.plot(_x_, orig_accs[0], c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    ax1.plot(_x_, white_accs[0], c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    ax1.plot(_x_, black_accs[0], c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax1.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    ax1.plot(_x_, pois_accs[0], '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    \"\"\"\n",
    "    mean1 = np.array(orig_dimp).mean(0)\n",
    "    std1 = np.array(orig_dimp).std(0)\n",
    "    mean2 = np.array(white_dimp).mean(0)\n",
    "    std2 = np.array(white_dimp).std(0)\n",
    "    mean3 = np.array(black_dimp).mean(0)\n",
    "    std3 = np.array(black_dimp).std(0)\n",
    "    mean4 = np.array(pois_dimp).mean(0)\n",
    "    std4 = np.array(pois_dimp).std(0)\n",
    "\n",
    "    \n",
    "    ax2=fig.add_subplot(gs[0,1]) # First row, second column\n",
    "    ax2.set_title(\"Demographic parity\")\n",
    "    \n",
    "    ax2.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax2.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax2.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax2.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax2.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax2.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax2.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax2.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    #ax2.plot(_x_, mean0, c=\"gray\", label=\"Original data\")\n",
    "    #ax2.fill_between(_x_, mean0-std0, mean0+std0 ,alpha=ALPHA, color=\"gray\")\n",
    "    ax2.legend(bbox_to_anchor=(1.1, -0.1),fontsize=15)\n",
    "    \n",
    "    \n",
    "    mean1 = np.array(orig_odds).mean(0)\n",
    "    std1 = np.array(orig_odds).std(0)\n",
    "    mean2 = np.array(white_odds).mean(0)\n",
    "    std2 = np.array(white_odds).std(0)\n",
    "    mean3 = np.array(black_odds).mean(0)\n",
    "    std3 = np.array(black_odds).std(0)\n",
    "    mean4 = np.array(pois_odds).mean(0)\n",
    "    std4 = np.array(pois_odds).std(0)\n",
    "    \n",
    "    ax2b=fig.add_subplot(gs[0,2]) # First row, second column\n",
    "    ax2b.set_title(\"Average odds difference\")\n",
    "\n",
    "    ax2b.plot(_x_, mean1, c=\"darkgreen\", label=\"Original classifier.\")\n",
    "    #ax2b.fill_between(_x_, mean1-std1, mean1+std1 ,alpha=ALPHA, color=\"darkgreen\")\n",
    "    ax2b.plot(_x_, mean2, c=\"red\", label=\"Poisoned classifier.White box attack\")\n",
    "    #ax2b.fill_between(_x_, mean2-std2, mean2+std2 ,alpha=ALPHA, color=\"red\")\n",
    "    ax2b.plot(_x_, mean3, c=\"orange\", label=\"Poisoned classifier. Black box attack\")\n",
    "    #ax2b.fill_between(_x_, mean3-std3, mean3+std3 ,alpha=ALPHA, color=\"orange\")\n",
    "    #ax2b.plot(_x_, mean4, '--', c=\"blue\", label=\"Error-generic poisoning attack\")\n",
    "    #ax2b.fill_between(_x_, mean4-std4, mean4+std4 ,alpha=ALPHA, color=\"blue\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_use_case_multiple_runs_v2(_results, np.ones(9), _x_=RANGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train_models2(ms, black_model, train_set, black_train_set, test_set, sensitive_att):\n",
    "    \n",
    "    accs = []\n",
    "    dimp = []\n",
    "    avg_odds = []\n",
    "    \n",
    "    fpr_priv = []\n",
    "    fpr_unpriv = []\n",
    "    fnr_priv = []\n",
    "    fnr_unpriv = []\n",
    "    \n",
    "    y_test = test_set.Y.get_data()\n",
    "    \n",
    "    for m in ms:\n",
    "        #m = m.fit(train_set)\n",
    "        _preds = m.predict(test_set.X).get_data()\n",
    "        accs.append(accuracy_score(y_test, _preds))\n",
    "        dimp.append(calculate_disparate_impact(_preds, sensitive_att))\n",
    "        avg_odds.append(get_average_odds_difference(y_test, _preds, sensitive_att))\n",
    "        \n",
    "        errors = get_error_rates(y_test, _preds, sensitive_att)\n",
    "        \n",
    "        fnr_priv.append(errors[0]['FNR_privileged'])\n",
    "        fnr_unpriv.append(errors[0]['FNR_unprivileged'])\n",
    "        \n",
    "        fpr_priv.append(errors[1]['FPR_privileged'])\n",
    "        fpr_unpriv.append(errors[1]['FPR_unprivileged'])\n",
    "\n",
    "    #black_model = black_model.fit(black_train_set)   \n",
    "    _preds2 = black_model.predict(test_set.X).get_data()\n",
    "    \n",
    "    accs.append(accuracy_score(y_test, _preds2))\n",
    "    dimp.append(calculate_disparate_impact(_preds2, sensitive_att))\n",
    "    avg_odds.append(get_average_odds_difference(y_test, _preds2, sensitive_att))  \n",
    "    errors = get_error_rates(y_test, _preds2, sensitive_att)\n",
    "        \n",
    "    fnr_priv.append(errors[0]['FNR_privileged'])\n",
    "    fnr_unpriv.append(errors[0]['FNR_unprivileged'])\n",
    "\n",
    "    fpr_priv.append(errors[1]['FPR_privileged'])\n",
    "    fpr_unpriv.append(errors[1]['FPR_unprivileged'])\n",
    "\n",
    "    return accs,dimp,avg_odds, fnr_priv, fnr_unpriv, fpr_priv, fpr_unpriv\n",
    "    \n",
    "accs = []\n",
    "dimps = []\n",
    "odds_means = []\n",
    "_tmp = []\n",
    "for i in range(len(_results[0])):\n",
    "    \n",
    "    t = []\n",
    "    for j in range(len(_results)):\n",
    "    \n",
    "\n",
    "        sc = _results[j][i]\n",
    "        tr = sc['training']\n",
    "        ts = sc['test']\n",
    "        ps = sc['white_poisoned_points']\n",
    "        ps2 = sc['black_poisoned_points']\n",
    "        \n",
    "        m1 = sc['original_classifier']\n",
    "        m2 = sc['white_poisoned_classifier']\n",
    "        black_m = sc['black_poisoned_classifier']\n",
    "        m4 = sc['normal_poisoned_classifier']\n",
    "        ms = [m1,m2]\n",
    "        \n",
    "        tr = tr.deepcopy().append(ps)\n",
    "        tr2 = tr.deepcopy().append(ps2)\n",
    "        \n",
    "        sensitive_att = sc['test_sensible_att']\n",
    "        \n",
    "        for z in range(3):\n",
    "            t.append(train_models2(ms, black_m, tr, tr2, ts, sensitive_att))\n",
    "\n",
    "    accs = [c[0] for c in t]\n",
    "    dimps = [c[1] for c in t]\n",
    "    odds = [c[2] for c in t]\n",
    "    fnr_priv = [c[3] for c in t] \n",
    "    fnr_unpriv = [c[4] for c in t]\n",
    "    fpr_priv = [c[5] for c in t]\n",
    "    fpr_unpriv = [c[6] for c in t]\n",
    "\n",
    "    accs_means = np.array(accs).mean(0)\n",
    "    dimp_means = np.array(dimps).mean(0)\n",
    "    odds_means = np.array(odds).mean(0)\n",
    "    fnr_p_means = np.array(fnr_priv).mean(0)\n",
    "    fnr_u_means = np.array(fnr_unpriv).mean(0)\n",
    "    fpr_p_means = np.array(fpr_priv).mean(0)\n",
    "    fpr_u_means = np.array(fpr_unpriv).mean(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    _tmp.append((accs_means, dimp_means, odds_means,fnr_p_means,fnr_u_means,fpr_p_means,fpr_u_means))\n",
    "\n",
    "accs = [c[0] for c in _tmp]\n",
    "dimps = [c[1] for c in _tmp]\n",
    "odds = [c[2] for c in _tmp]\n",
    "fnr_priv = [c[3] for c in _tmp] \n",
    "fnr_unpriv = [c[4] for c in _tmp]\n",
    "fpr_priv = [c[5] for c in _tmp]\n",
    "fpr_unpriv = [c[6] for c in _tmp]\n",
    "\n",
    "models = [\"Original model\", \"White-box attack\",\"Black-box attack\"]\n",
    "model_cs = ['g', 'r', 'orange']\n",
    "model_ms = ['^', (8,2,0), 'v', 'o', '+', '*']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[16,8])\n",
    "\n",
    "gs=GridSpec(2,4) # 2 rows, 4 columns\n",
    "\n",
    "ax=fig.add_subplot(gs[0,:2]) # Second row, span all columns\n",
    "\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    ax.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax.set_xlabel(\"Euclidean distance in data\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(gs[0,2]) # Second row, span all columns\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax2.set_xlabel(\"Euclidean distance\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(gs[0,3])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax3.set_xlabel(\"Euclidean distance\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    "\n",
    "ax4=fig.add_subplot(gs[1,0])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fnr_p[i] for fnr_p in fnr_priv]\n",
    "    ax4.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax4.set_xlabel(\"Euclidean distance\")\n",
    "ax4.set_title(\"FNR privileged\")\n",
    "\n",
    "ax5=fig.add_subplot(gs[1,1])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fnr_up[i] for fnr_up in fnr_unpriv]\n",
    "    ax5.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax5.set_xlabel(\"Euclidean distance\")\n",
    "ax5.set_title(\"FNR unprivileged\")\n",
    "\n",
    "ax6=fig.add_subplot(gs[1,2])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fpr_p[i] for fpr_p in fpr_priv]\n",
    "    ax6.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax6.set_xlabel(\"Euclidean distance\")\n",
    "ax6.set_title(\"FPR privileged\")\n",
    "\n",
    "ax7=fig.add_subplot(gs[1,3])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [fpr_up[i] for fpr_up in fpr_unpriv]\n",
    "    ax7.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax7.set_xlabel(\"Euclidean distance\")\n",
    "ax7.set_title(\"FPR unprivileged\")\n",
    "\n",
    " \n",
    "ax6.legend(bbox_to_anchor=(1.3, -.2), fontsize=15, ncol=3)\n",
    "fig.suptitle(\"Performance of attacks on synthetic data\", x=0.5, y=1)\n",
    "\n",
    "\n",
    "\n",
    "fig.align_labels() \n",
    "plt.show()\n",
    "fig.savefig(\"attack_synthetic_data2.eps\", format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=[16,4])\n",
    "\n",
    "gs=GridSpec(1,3) # 2 rows, 4 columns\n",
    "\n",
    "ax=fig.add_subplot(gs[0,0]) # Second row, span all columns\n",
    "\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [acc[i] for acc in accs]\n",
    "    ax.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax.set_xlabel(\"Euclidean distance in data\")\n",
    "ax.set_title(\"Accuracy\")\n",
    "\n",
    "\n",
    "ax2=fig.add_subplot(gs[0,1]) # Second row, span all columns\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "for i in range(len(accs[0])):\n",
    "    t = [dimp[i] for dimp in dimps]\n",
    "    ax2.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax2.set_xlabel(\"Euclidean distance\")\n",
    "ax2.set_title(\"Demographic parity\")\n",
    "\n",
    "\n",
    "ax3=fig.add_subplot(gs[0,2])\n",
    "\n",
    "_x_ = list(range(len(_results[0])))\n",
    "\n",
    "for i in range(len(accs[0])):\n",
    "    t = [odd[i] for odd in odds]\n",
    "    ax3.plot(_x_,t,c=model_cs[i],marker=model_ms[i],ls=':',label=models[i])\n",
    "    \n",
    "#ax.set_xlabel(_x_)    \n",
    "#ax3.set_xlabel(\"Euclidean distance\")\n",
    "ax3.set_title(\"Average odds difference\")\n",
    "\n",
    "\n",
    "ax.legend(bbox_to_anchor=(2.6, -.2), fontsize=15, ncol=3)\n",
    "fig.suptitle(\"Performance of attacks on synthetic data\", x=0.5, y=1.2)\n",
    "\n",
    "\n",
    "\n",
    "fig.align_labels() \n",
    "plt.show()\n",
    "fig.savefig(\"attack_synthetic_data2.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dimps = dimps[1:]\n",
    "_metrics = [accs,dimps,odds,fnr_priv,fnr_unpriv,fpr_priv,fpr_unpriv]\n",
    "_metric_names = [\"Accuracy\", \"Demographic parity\", \"Average odds difference\", \"FNR priv\", \"FNR unpriv\", \"FPR priv\", \"FPR unpriv\"]\n",
    "for m_idx, m in enumerate(_metrics):\n",
    "    m = np.array(m)\n",
    "    if m_idx != 3:\n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,1]/m[:,0])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,2]/m[:,0])))\n",
    "    else:        \n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,1][:-1] / m[:,0][:-1])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,2][:-1] / m[:,0][:-1])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fnr_priv = np.array(fnr_priv)\n",
    "np.mean(fnr_priv[:,1]/fnr_priv[:,0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fnr_priv[:,1][:-1] / fnr_priv[:,0][:-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "dimps = dimps[1:]\n",
    "_metrics = [accs,dimps,odds,fnr_priv,fnr_unpriv,fpr_priv,fpr_unpriv]\n",
    "_metric_names = [\"Accuracy\", \"Demographic parity\", \"Average odds difference\", \"FNR priv\", \"FNR unpriv\", \"FPR priv\", \"FPR unpriv\"]\n",
    "for m_idx, m in enumerate(_metrics):\n",
    "    m = np.array(m)\n",
    "    if m_idx != 3:\n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,1]/m[:,0])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,2]/m[:,0])))\n",
    "    else:        \n",
    "        print(\" -- {} -- \".format(_metric_names[m_idx]))\n",
    "        print(\" White/Orig: {}\".format(np.mean(m[:,1][:-1] / m[:,0][:-1])))\n",
    "        print(\" Black/Orig: {}\".format(np.mean(m[:,2][:-1] / m[:,0][:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fnr_priv = np.array(fnr_priv)\n",
    "np.mean(fnr_priv[:,1]/fnr_priv[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fnr_priv[:,1][:-1] / fnr_priv[:,0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}